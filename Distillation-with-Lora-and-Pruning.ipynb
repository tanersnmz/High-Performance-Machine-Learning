{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b726e87",
   "metadata": {},
   "source": [
    "# The Experments about LoRA and Purning based on Knowledge Distilled GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import torch\n",
    "import time, math, logging\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GenerationConfig,AutoModelForCausalLM\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft.tuners.lora import LoraLayer\n",
    "import torch.nn.utils.prune as prune\n",
    "import pandas as pd\n",
    "import gc\n",
    "import copy\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# Define experiment parameters\n",
    "model_name = \"gpt2\"\n",
    "max_length = 128\n",
    "num_train_epochs = 2\n",
    "eval_every_steps = 200\n",
    "batch_size = 16\n",
    "inference_batch_size = 8\n",
    "num_inference_batches = 50\n",
    "pruning_amount = 0.8  # 80% pruning rate\n",
    "lora_r = 8  # LoRA rank\n",
    "lora_alpha = 32\n",
    "lora_target_modules = [\"c_attn\"]  # Target attention modules for LoRA\n",
    "baseline_lr = 5e-5\n",
    "lora_lr = 1e-4\n",
    "run_inference_benchmark = True\n",
    "\n",
    "# Initialize wandb for experiment tracking\n",
    "try:\n",
    "    run = wandb.init(\n",
    "        project=\"lora-pruning-comparison-dstill-3\",\n",
    "        name=f\"Baseline_vs_LoRA_vs_Pruned_{num_train_epochs}Ep_{pruning_amount:.0%}\",\n",
    "        config={\n",
    "            \"model_name\": model_name, \"max_length\": max_length,\n",
    "            \"num_train_epochs\": num_train_epochs, \"batch_size\": batch_size,\n",
    "            \"pruning_amount\": pruning_amount, \"lora_r\": lora_r,\n",
    "            \"lora_alpha\": lora_alpha, \"lora_target_modules\": lora_target_modules,\n",
    "            \"baseline_lr\": baseline_lr, \"lora_lr\": lora_lr,\n",
    "            \"eval_every_steps\": eval_every_steps, \"device\": str(device),\n",
    "            \"inference_batch_size\": inference_batch_size,\n",
    "            \"num_inference_batches\": num_inference_batches,\n",
    "            \"run_inference_benchmark\": run_inference_benchmark\n",
    "        }\n",
    "    )\n",
    "    logger.info(\"Weights & Biases initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to initialize Weights & Biases: {e}\")\n",
    "    run = None\n",
    "\n",
    "# Load and prepare dataset\n",
    "logger.info(\"Loading data...\")\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_texts_full = [t for t in dataset[\"train\"][\"text\"] if t.strip()]\n",
    "val_texts_full = [t for t in dataset[\"validation\"][\"text\"] if t.strip()]\n",
    "test_texts_full = val_texts_full[:inference_batch_size * num_inference_batches]\n",
    "logger.info(f\"Data loaded. Train: {len(train_texts_full)}, Val/Test: {len(val_texts_full)}\")\n",
    "\n",
    "# Function to calculate perplexity for model evaluation\n",
    "@torch.no_grad()\n",
    "def compute_perplexity(model, tokenizer, texts, device, batch_size=8, max_length=128):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    total_evaluated = 0\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        if not batch: continue\n",
    "        total_evaluated += len(batch)\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs, labels=inputs.input_ids)\n",
    "        if hasattr(outputs, 'loss') and outputs.loss is not None:\n",
    "            losses.append(outputs.loss.item() * len(batch))\n",
    "    if not losses or total_evaluated == 0: return float('inf')\n",
    "    avg_loss = sum(losses) / total_evaluated\n",
    "    if avg_loss <= 0: return float('inf')\n",
    "    return math.exp(avg_loss)\n",
    "\n",
    "# Function for model training with tracking\n",
    "def train_fixed_duration(model, tokenizer, train_texts, val_texts, num_epochs,\n",
    "                         device, lr=5e-5, batch_size=8, max_length=128,\n",
    "                         eval_every=500, run_label=\"Training\"):\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    start_time = time.time()\n",
    "    peak_mem_overall = 0\n",
    "\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "    total_expected_steps = (len(train_texts) // batch_size) * num_epochs\n",
    "    step = 0\n",
    "    all_val_ppl = []\n",
    "    steps_log = []\n",
    "\n",
    "    logger.info(f\"--- Starting {run_label} ---\")\n",
    "    logger.info(f\"Epochs: {num_epochs}, LR: {lr}, Batch Size: {batch_size}, Eval Every: {eval_every}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        logger.info(f\"[{run_label} Epoch {epoch+1}/{num_epochs}] Starting...\")\n",
    "        progress_bar = tqdm(range(0, len(train_texts), batch_size), desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "        for i in progress_bar:\n",
    "            batch = train_texts[i:i+batch_size]\n",
    "            if not batch: continue\n",
    "\n",
    "            inputs = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "            outputs = model(**inputs, labels=inputs.input_ids)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            if loss is None or torch.isnan(loss):\n",
    "                logger.warning(f\"[{run_label} Step {step}] Loss is None or NaN. Skipping step.\")\n",
    "                step += 1\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            step += 1\n",
    "\n",
    "            progress_bar.set_postfix({'loss': f\"{loss.item():.3f}\"})\n",
    "\n",
    "            is_last_batch_overall = (epoch == num_epochs - 1 and i + batch_size >= len(train_texts))\n",
    "            if step % eval_every == 0 or is_last_batch_overall:\n",
    "                current_loss_val = loss.item() if loss is not None else float('nan')\n",
    "                val_ppl = compute_perplexity(model, tokenizer, val_texts, device, batch_size=batch_size, max_length=max_length)\n",
    "                if not math.isinf(val_ppl) and not math.isnan(val_ppl):\n",
    "                    all_val_ppl.append(val_ppl)\n",
    "                    steps_log.append(step)\n",
    "\n",
    "                elapsed_h = (time.time() - start_time) / 3600\n",
    "                current_peak_mem = 0\n",
    "                if device == torch.device(\"cuda\"):\n",
    "                    current_peak_mem = torch.cuda.max_memory_allocated(device) / 1024**2\n",
    "                    peak_mem_overall = max(peak_mem_overall, current_peak_mem)\n",
    "\n",
    "                logger.info(f\"[{run_label} Step {step}/{total_expected_steps}] val_ppl={val_ppl:.2f} loss={current_loss_val:.3f} time={elapsed_h:.2f}h peak_mem={current_peak_mem:.1f}MB\")\n",
    "\n",
    "                if run:\n",
    "                     wandb.log({\n",
    "                         f\"{run_label}/Step\": step, f\"{run_label}/Val Perplexity\": val_ppl,\n",
    "                         f\"{run_label}/Loss\": current_loss_val, f\"{run_label}/Elapsed Hours\": elapsed_h,\n",
    "                         f\"{run_label}/Current Peak Mem MB\": current_peak_mem\n",
    "                     }, step=step)\n",
    "                model.train()\n",
    "\n",
    "        logger.info(f\"[{run_label} Epoch {epoch+1}/{num_epochs}] Completed.\")\n",
    "\n",
    "    total_h = (time.time() - start_time) / 3600\n",
    "    final_mem = peak_mem_overall\n",
    "    final_ppl = all_val_ppl[-1] if all_val_ppl else float('inf')\n",
    "\n",
    "    logger.info(f\"--- Finished {run_label} ---\")\n",
    "    return {\n",
    "        \"steps\": step, \"total_hours\": total_h, \"peak_mem_mb\": final_mem,\n",
    "        \"final_ppl\": final_ppl, \"steps_log\": steps_log, \"ppl_log\": all_val_ppl\n",
    "    }\n",
    "\n",
    "# Function to apply pruning to model parameters\n",
    "def apply_pruning(model_to_prune, amount):\n",
    "    parameters_to_prune = []\n",
    "    target_modules = set()\n",
    "    logger.debug(\"Starting parameter search for pruning...\")\n",
    "    for name, module in model_to_prune.named_modules():\n",
    "         if isinstance(module, LoraLayer):\n",
    "             logger.debug(f\"Found LoraLayer: {name}\")\n",
    "             for key in ['lora_A', 'lora_B']:\n",
    "                if hasattr(module, key):\n",
    "                    sub_module_dict = getattr(module, key)\n",
    "                    if isinstance(sub_module_dict, torch.nn.ModuleDict):\n",
    "                         for adapter_name, sub_module in sub_module_dict.items():\n",
    "                             if hasattr(sub_module, 'weight'):\n",
    "                                logger.debug(f\"   Found weight in {key}.{adapter_name}. Adding.\")\n",
    "                                parameters_to_prune.append((sub_module, 'weight'))\n",
    "                                target_modules.add(sub_module)\n",
    "                    elif isinstance(sub_module_dict, torch.nn.Module):\n",
    "                        if hasattr(sub_module_dict, 'weight'):\n",
    "                            logger.debug(f\"   Found weight directly in {key}. Adding.\")\n",
    "                            parameters_to_prune.append((sub_module_dict, 'weight'))\n",
    "                            target_modules.add(sub_module_dict)\n",
    "\n",
    "    if not parameters_to_prune:\n",
    "        logger.warning(\"Could not find any LoRA parameters to prune!\")\n",
    "        return 0.0\n",
    "    else:\n",
    "        logger.info(f\"Identified {len(parameters_to_prune)} parameter tensors for pruning.\")\n",
    "        prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=amount)\n",
    "        logger.info(\"Pruning mask applied. Making pruning permanent...\")\n",
    "        final_total_params = 0; final_zero_params = 0; pruned_module_count = 0\n",
    "        for module in target_modules:\n",
    "            is_currently_pruned = prune.is_pruned(module)\n",
    "            if is_currently_pruned:\n",
    "                 try:\n",
    "                     mask = getattr(module, 'weight_mask', None); orig_param = getattr(module, 'weight_orig', None)\n",
    "                     if mask is not None and orig_param is not None:\n",
    "                          param_element_count = orig_param.nelement(); param_zero_count = torch.sum(mask == 0).item()\n",
    "                          final_total_params += param_element_count; final_zero_params += param_zero_count\n",
    "                     elif hasattr(module, 'weight'):\n",
    "                          param = getattr(module, 'weight'); final_total_params += param.nelement(); final_zero_params += torch.sum(param == 0).item()\n",
    "                 except AttributeError:\n",
    "                       if hasattr(module, 'weight'):\n",
    "                           param = getattr(module, 'weight'); final_total_params += param.nelement(); final_zero_params += torch.sum(param == 0).item()\n",
    "                 prune.remove(module, 'weight'); pruned_module_count += 1\n",
    "            elif hasattr(module, 'weight'):\n",
    "                 param = getattr(module, 'weight'); final_total_params += param.nelement()\n",
    "        logger.info(f\"Removed pruning buffer from {pruned_module_count} modules.\")\n",
    "        if final_total_params > 0:\n",
    "            final_sparsity = 100. * float(final_zero_params) / float(final_total_params)\n",
    "            logger.info(f\"Pruning made permanent. Calculated sparsity: {final_sparsity:.2f}%\")\n",
    "            return final_sparsity\n",
    "        else:\n",
    "            logger.info(\"Pruning made permanent (no parameters found or counted).\"); return 0.0\n",
    "\n",
    "# Function for inference benchmarking\n",
    "@torch.no_grad()\n",
    "def benchmark_inference(model, tokenizer, texts, device, batch_size=8, max_length=128, num_batches=50, generation=False):\n",
    "    model.eval()\n",
    "    latencies = []\n",
    "    total_samples = 0\n",
    "    logger.info(f\"--- Starting Inference Benchmark (Generation: {generation}) ---\")\n",
    "    generation_config = GenerationConfig(max_new_tokens=5, pad_token_id=tokenizer.pad_token_id) if generation else None\n",
    "\n",
    "    for i in tqdm(range(0, min(len(texts), batch_size * num_batches), batch_size), desc=\"Inference\", leave=False):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        if not batch: continue\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "        batch_samples = inputs['input_ids'].shape[0]\n",
    "        total_samples += batch_samples\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        if generation:\n",
    "            _ = model.generate(**inputs, generation_config=generation_config)\n",
    "        else:\n",
    "            _ = model(**inputs)\n",
    "        if device == torch.device(\"cuda\"): torch.cuda.synchronize()\n",
    "        end_time = time.perf_counter()\n",
    "        latencies.append(end_time - start_time)\n",
    "\n",
    "    avg_latency_batch = np.mean(latencies) if latencies else 0\n",
    "    throughput_samples_sec = total_samples / sum(latencies) if latencies else 0\n",
    "    avg_latency_sample = (sum(latencies) / total_samples) * 1000 if total_samples > 0 else 0\n",
    "\n",
    "    logger.info(f\"--- Finished Inference Benchmark ---\")\n",
    "    return {\n",
    "        \"avg_inference_latency_ms_per_sample\": avg_latency_sample,\n",
    "        \"avg_inference_throughput_samples_sec\": throughput_samples_sec\n",
    "    }\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=lora_r, lora_alpha=lora_alpha, target_modules=lora_target_modules,\n",
    "    lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "all_results = {}\n",
    "trained_models = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3474e",
   "metadata": {},
   "source": [
    "##  Train LoRA model(distilled model) with pre-pruning (pruning applied BEFORE training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e612571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time, math, logging\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GenerationConfig,AutoModelForCausalLM\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft.tuners.lora import LoraLayer\n",
    "import torch.nn.utils.prune as prune\n",
    "import pandas as pd\n",
    "import gc\n",
    "import copy\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "logger.info(\"\\n===== Starting LoRA Pre-Pruned on Distilled Model =====\")\n",
    "try:\n",
    "    model_distilled_base = AutoModelForCausalLM.from_pretrained(\"./distilled_model\").to(device)\n",
    "    for param in model_distilled_base.parameters(): param.requires_grad = False\n",
    "\n",
    "    lora_model_distilled = get_peft_model(model_distilled_base, lora_cfg)\n",
    "    lora_model_distilled.print_trainable_parameters()\n",
    "\n",
    "    logger.info(f\"Applying {pruning_amount:.1%} pruning to distilled LoRA model BEFORE training...\")\n",
    "    apply_pruning(lora_model_distilled, pruning_amount)\n",
    "    logger.info(\"Pruned distilled LoRA model.\")\n",
    "\n",
    "    distilled_lora_res = train_fixed_duration(\n",
    "        lora_model_distilled, tokenizer, train_texts_full, val_texts_full,\n",
    "        num_epochs=num_train_epochs, device=device, lr=lora_lr,\n",
    "        batch_size=batch_size, max_length=max_length,\n",
    "        eval_every=eval_every_steps, run_label=\"Distilled LoRA Pre-Pruned\"\n",
    "    )\n",
    "    logger.info(f\"Distilled LoRA Pre-Pruned results: {distilled_lora_res}\")\n",
    "\n",
    "    if 'final_ppl' in distilled_lora_res:\n",
    "        all_results[\"Distilled LoRA Pre-Pruned\"] = distilled_lora_res\n",
    "        trained_models[\"Distilled LoRA Pre-Pruned\"] = copy.deepcopy(lora_model_distilled)\n",
    "        if run:\n",
    "            wandb.log({f\"Summary/Distilled LoRA Pre-Pruned/{k}\": v for k, v in distilled_lora_res.items() if 'log' not in k})\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to train LoRA Pre-Pruned on Distilled model: {e}\")\n",
    "\n",
    "\n",
    "#===============================================   \n",
    "distilled_lora_model_path = \"./distilled_lora_prepruned\"\n",
    "\n",
    "os.makedirs(distilled_lora_model_path, exist_ok=True)\n",
    "lora_model_distilled.save_pretrained(distilled_lora_model_path)\n",
    "logger.info(f\"Distilled LoRA Pre-Pruned model saved to {distilled_lora_model_path}\")    \n",
    "    \n",
    "del model_distilled_base, lora_model_distilled; gc.collect(); torch.cuda.empty_cache() if device == torch.device(\"cuda\") else None\n",
    "\n",
    "\n",
    "if run_inference_benchmark:\n",
    "    logger.info(\"\\n===== Starting Inference Benchmarks =====\")\n",
    "    for label, model in trained_models.items():\n",
    "        if model is not None:\n",
    "            logger.info(f\"--- Benchmarking Inference for: {label} ---\")\n",
    "            inference_res_fwd = benchmark_inference(\n",
    "                model, tokenizer, test_texts_full, device,\n",
    "                batch_size=inference_batch_size, max_length=max_length,\n",
    "                num_batches=num_inference_batches, generation=False\n",
    "            )\n",
    "            inference_res_gen = benchmark_inference(\n",
    "                model, tokenizer, test_texts_full, device,\n",
    "                batch_size=inference_batch_size, max_length=max_length,\n",
    "                num_batches=num_inference_batches // 2,\n",
    "                generation=True\n",
    "            )\n",
    "            all_results[label].update({\n",
    "                 \"fwd_pass_latency_ms\": inference_res_fwd[\"avg_inference_latency_ms_per_sample\"],\n",
    "                 \"fwd_pass_throughput\": inference_res_fwd[\"avg_inference_throughput_samples_sec\"],\n",
    "                 \"gen_latency_ms\": inference_res_gen[\"avg_inference_latency_ms_per_sample\"],\n",
    "                 \"gen_throughput\": inference_res_gen[\"avg_inference_throughput_samples_sec\"]\n",
    "            })\n",
    "            logger.info(f\"Inference Results for {label}: Fwd Latency={inference_res_fwd['avg_inference_latency_ms_per_sample']:.2f}ms, Gen Latency={inference_res_gen['avg_inference_latency_ms_per_sample']:.2f}ms\")\n",
    "            if run:\n",
    "                wandb.log({\n",
    "                    f\"Summary/{label}/Fwd Pass Latency ms\": inference_res_fwd[\"avg_inference_latency_ms_per_sample\"],\n",
    "                    f\"Summary/{label}/Fwd Pass Throughput\": inference_res_fwd[\"avg_inference_throughput_samples_sec\"],\n",
    "                    f\"Summary/{label}/Gen Latency ms\": inference_res_gen[\"avg_inference_latency_ms_per_sample\"],\n",
    "                    f\"Summary/{label}/Gen Throughput\": inference_res_gen[\"avg_inference_throughput_samples_sec\"]\n",
    "                })\n",
    "        else:\n",
    "            logger.warning(f\"Skipping inference benchmark for {label} as training failed.\")\n",
    "        if model is not None: del model\n",
    "        gc.collect(); torch.cuda.empty_cache() if device == torch.device(\"cuda\") else None\n",
    "    trained_models = {}\n",
    "\n",
    "logger.info(\"\\n===== Generating Learning Curve Plot =====\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_data_logged = False\n",
    "for label, results in all_results.items():\n",
    "    if \"steps_log\" in results and \"ppl_log\" in results and results[\"steps_log\"] and results[\"ppl_log\"]:\n",
    "        steps_axis = np.array(results[\"steps_log\"])\n",
    "        ppl_values = np.array(results[\"ppl_log\"])\n",
    "        mask = np.isfinite(ppl_values)\n",
    "        if np.any(mask):\n",
    "             plt.plot(steps_axis[mask], ppl_values[mask], marker='.', linestyle='-', label=label)\n",
    "             plot_data_logged = True\n",
    "        else:\n",
    "             logger.warning(f\"No valid PPL data points to plot for {label}.\")\n",
    "\n",
    "if plot_data_logged:\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Validation Perplexity\")\n",
    "    plt.title(\"Perplexity vs. Training Steps\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    min_ppl_overall = min(min(r[\"ppl_log\"]) for r in all_results.values() if r and r.get(\"ppl_log\")) if any(r and r.get(\"ppl_log\") for r in all_results.values()) else 7\n",
    "    plt.ylim(bottom=max(5, min(min_ppl_overall - 0.5, 7))) \n",
    "\n",
    "    if run:\n",
    "        try:\n",
    "            wandb.log({\"Learning Curve\": wandb.Image(plt)})\n",
    "            logger.info(\"Learning curve plot logged to Weights & Biases.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to log plot to wandb: {e}\")\n",
    "    plt.close()\n",
    "else:\n",
    "     logger.warning(\"No valid data found to generate learning curve plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de34f27",
   "metadata": {},
   "source": [
    "# Generate final comparison tables and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b658d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n===== Final Benchmark Comparison =====\")\n",
    "results_list = []\n",
    "indices = []\n",
    "\n",
    "if \"Baseline\" in all_results:\n",
    "    results_list.append(all_results[\"Baseline\"])\n",
    "    indices.append(\"Baseline\")\n",
    "if \"LoRA Standard\" in all_results:\n",
    "    results_list.append(all_results[\"LoRA Standard\"])\n",
    "    indices.append(\"LoRA Standard\")\n",
    "if \"LoRA Pre-Pruned\" in all_results:\n",
    "    results_list.append(all_results[\"LoRA Pre-Pruned\"])\n",
    "    indices.append(f\"LoRA Pre-Pruned ({pruning_amount:.0%})\")\n",
    "    \n",
    "if \"Distilled LoRA Pre-Pruned\" in all_results:\n",
    "    results_list.append(all_results[\"Distilled LoRA Pre-Pruned\"])\n",
    "    indices.append(\"Distilled LoRA Pre-Pruned\")\n",
    "\n",
    "if results_list:\n",
    "    df = pd.DataFrame(results_list, index=indices)\n",
    "    df_display = df.drop(columns=['ppl_log', 'steps_log'], errors='ignore')\n",
    "\n",
    "    cols_to_rename = {\n",
    "        \"steps\": \"Total Steps\", \"total_hours\": \"Total Hours (h)\",\n",
    "        \"peak_mem_mb\": \"Peak GPU Mem (MB)\", \"final_ppl\": \"Final Val PPL\"\n",
    "    }\n",
    "    if run_inference_benchmark:\n",
    "        cols_to_rename.update({\n",
    "            \"fwd_pass_latency_ms\": \"Fwd Latency (ms)\", \"fwd_pass_throughput\": \"Fwd TP (samples/s)\",\n",
    "            \"gen_latency_ms\": \"Gen Latency (ms)\", \"gen_throughput\": \"Gen TP (samples/s)\"\n",
    "        })\n",
    "\n",
    "    df_display.rename(columns=cols_to_rename, inplace=True)\n",
    "\n",
    "    format_map = {\n",
    "        \"Total Steps\": '{:,.0f}', \"Total Hours (h)\": '{:.2f}',\n",
    "        \"Peak GPU Mem (MB)\": '{:,.1f}', \"Final Val PPL\": '{:.2f}',\n",
    "        \"Fwd Latency (ms)\": '{:.1f}', \"Fwd TP (samples/s)\": '{:.1f}',\n",
    "        \"Gen Latency (ms)\": '{:.1f}', \"Gen TP (samples/s)\": '{:.1f}'\n",
    "    }\n",
    "    for col, fmt in format_map.items():\n",
    "        if col in df_display.columns:\n",
    "            try:\n",
    "                df_display[col] = df_display[col].map(lambda x: fmt.format(x) if pd.notnull(x) else 'N/A')\n",
    "            except (TypeError, ValueError):\n",
    "                 logger.warning(f\"Could not format column {col}. Skipping formatting.\")\n",
    "\n",
    "\n",
    "    logger.info(\"\\nComparison DataFrame:\\n%s\", df_display.to_string())\n",
    "\n",
    "    if run:\n",
    "        try:\n",
    "            df_log = df_display.reset_index().rename(columns={'index': 'Method'})\n",
    "            wandb.log({\"Comparison Table\": wandb.Table(dataframe=df_log)})\n",
    "            logger.info(\"Comparison table logged to Weights & Biases.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to log DataFrame to Weights & Biases: {e}\")\n",
    "\n",
    "else:\n",
    "    logger.error(\"No successful benchmark runs to compare.\")\n",
    "\n",
    "if run:\n",
    "    wandb.finish()\n",
    "    logger.info(\"Weights & Biases run finished.\")\n",
    "\n",
    "logger.info(\"\\n===== Script Finished =====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63223884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 23:40:28,764 - INFO - Loading wikitext-2 dataset...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import logging\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Loading wikitext-2 dataset...\")\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c24697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 23:42:54,195 - INFO - Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "base_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(base_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "distilled_model = GPT2LMHeadModel.from_pretrained( \"./saved_models/distilled_lora_prepruned\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b8c1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_inference(model, tokenizer, dataset, batch_size, max_length=128, num_batches=100):\n",
    "    import time, torch, numpy as np\n",
    "    device = next(model.parameters()).device\n",
    "    test_texts = [t for t in dataset[\"test\"][\"text\"] if t.strip()]\n",
    "\n",
    "    model.eval()\n",
    "    infer_times, infer_mems = [], []\n",
    "    infer_thrpts, infer_perps = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_batches):\n",
    "            batch = test_texts[i*batch_size:(i+1)*batch_size]\n",
    "            if not batch:\n",
    "                break\n",
    "\n",
    "            inputs = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "\n",
    "            start = time.time()\n",
    "            outputs = model(**inputs, labels=inputs.input_ids)\n",
    "            loss = outputs.loss\n",
    "            perp = torch.exp(loss).item()\n",
    "            elapsed = time.time() - start\n",
    "            mem = torch.cuda.memory_allocated(device) / 1024**2\n",
    "\n",
    "            infer_times.append(elapsed)\n",
    "            infer_mems.append(mem)\n",
    "            infer_thrpts.append(batch_size / elapsed)\n",
    "            infer_perps.append(perp)\n",
    "\n",
    "    return {\n",
    "        \"time\":       (np.mean(infer_times),   np.std(infer_times)),\n",
    "        \"memory\":     (np.mean(infer_mems),    np.std(infer_mems)),\n",
    "        \"throughput\": (np.mean(infer_thrpts),  np.std(infer_thrpts)),\n",
    "        \"perplexity\": (np.mean(infer_perps),   np.std(infer_perps))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b655f2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 23:51:41,950 - INFO - \n",
      "Running benchmark for Distilled LoRA model with batch_size=8, max_length=128\n",
      "2025-05-05 23:51:41,952 - INFO - Configuration:\n",
      "2025-05-05 23:51:41,952 - INFO -   • Model:  Distilled LoRA on GPT-2\n",
      "2025-05-05 23:51:41,953 - INFO -   • Batch size:   8\n",
      "2025-05-05 23:51:41,954 - INFO -   • Max length:   128\n",
      "2025-05-05 23:51:49,327 - INFO - \n",
      "Inference:\n",
      "2025-05-05 23:51:49,328 - INFO -   Average time per batch:    0.0673 ± 0.0170 seconds\n",
      "2025-05-05 23:51:49,329 - INFO -   Average memory usage:      1077.80 ± 73.01 MB\n",
      "2025-05-05 23:51:49,329 - INFO -   Average throughput:        149.14 ± 126.51 samples/second\n",
      "2025-05-05 23:51:49,330 - INFO -   Average perplexity:        11.5527 ± 7.8329\n",
      "2025-05-05 23:51:49,330 - INFO - \n",
      "Running benchmark for Distilled LoRA model with batch_size=16, max_length=128\n",
      "2025-05-05 23:51:49,331 - INFO - Configuration:\n",
      "2025-05-05 23:51:49,331 - INFO -   • Model:  Distilled LoRA on GPT-2\n",
      "2025-05-05 23:51:49,331 - INFO -   • Batch size:   16\n",
      "2025-05-05 23:51:49,332 - INFO -   • Max length:   128\n",
      "2025-05-05 23:52:04,326 - INFO - \n",
      "Inference:\n",
      "2025-05-05 23:52:04,327 - INFO -   Average time per batch:    0.1358 ± 0.0324 seconds\n",
      "2025-05-05 23:52:04,328 - INFO -   Average memory usage:      1363.48 ± 138.67 MB\n",
      "2025-05-05 23:52:04,328 - INFO -   Average throughput:        148.30 ± 136.07 samples/second\n",
      "2025-05-05 23:52:04,329 - INFO -   Average perplexity:        9.6614 ± 5.6837\n",
      "2025-05-05 23:52:04,329 - INFO - \n",
      "Running benchmark for Distilled LoRA model with batch_size=32, max_length=128\n",
      "2025-05-05 23:52:04,330 - INFO - Configuration:\n",
      "2025-05-05 23:52:04,331 - INFO -   • Model:  Distilled LoRA on GPT-2\n",
      "2025-05-05 23:52:04,331 - INFO -   • Batch size:   32\n",
      "2025-05-05 23:52:04,332 - INFO -   • Max length:   128\n",
      "2025-05-05 23:52:32,582 - INFO - \n",
      "Inference:\n",
      "2025-05-05 23:52:32,583 - INFO -   Average time per batch:    0.2852 ± 0.0438 seconds\n",
      "2025-05-05 23:52:32,583 - INFO -   Average memory usage:      1979.57 ± 182.88 MB\n",
      "2025-05-05 23:52:32,584 - INFO -   Average throughput:        121.53 ± 61.88 samples/second\n",
      "2025-05-05 23:52:32,584 - INFO -   Average perplexity:        8.4038 ± 4.1210\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "for bs in [8, 16, 32]:\n",
    "    logger.info(f\"\\nRunning benchmark for Distilled LoRA model with batch_size={bs}, max_length={max_length}\")\n",
    "    logger.info(\"Configuration:\")\n",
    "    logger.info(f\"  • Model:  Distilled LoRA on GPT-2\")\n",
    "    logger.info(f\"  • Batch size:   {bs}\")\n",
    "    logger.info(f\"  • Max length:   {max_length}\")\n",
    "\n",
    "    infer_stats = benchmark_inference(distilled_model, tokenizer, dataset, batch_size=bs)\n",
    "\n",
    "    # Inference results\n",
    "    i = infer_stats\n",
    "    logger.info(\"\\nInference:\")\n",
    "    logger.info(f\"  Average time per batch:    {i['time'][0]:.4f} ± {i['time'][1]:.4f} seconds\")\n",
    "    logger.info(f\"  Average memory usage:      {i['memory'][0]:.2f} ± {i['memory'][1]:.2f} MB\")\n",
    "    logger.info(f\"  Average throughput:        {i['throughput'][0]:.2f} ± {i['throughput'][1]:.2f} samples/second\")\n",
    "    logger.info(f\"  Average perplexity:        {i['perplexity'][0]:.4f} ± {i['perplexity'][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82caf89b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
