{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc49f0d3-ab30-4c38-a829-fec173b90c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Config, GPT2Tokenizer, BitsAndBytesConfig,AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch\n",
    "import platform\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import json, pprint\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft.tuners.lora import LoraLayer\n",
    "import copy, numpy as np, warnings\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f0d34f-b039-4c68-ae1a-b186ed7231f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.9\n",
      "PyTorch version: 2.3.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU model: Tesla T4\n",
      "Number of GPUs: 1\n",
      "Available GPU memory: 15.64 GB\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU model: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"No Cuda!\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "641b4f44-ce66-4ee3-9b82-e09e9e99105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(model, tokenizer, texts, device, batch_size=8, max_length=128):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    total_evaluated = 0\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        if not batch: continue\n",
    "        total_evaluated += len(batch)\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs, labels=inputs.input_ids)\n",
    "        if hasattr(outputs, 'loss') and outputs.loss is not None:\n",
    "            losses.append(outputs.loss.item() * len(batch))\n",
    "    if not losses or total_evaluated == 0: return float('inf')\n",
    "    avg_loss = sum(losses) / total_evaluated\n",
    "    if avg_loss <= 0: return float('inf')\n",
    "    return math.exp(avg_loss)\n",
    "    \n",
    "def apply_pruning(model_to_prune, amount):\n",
    "    parameters_to_prune = []\n",
    "    target_modules = set()\n",
    "    print(\"Starting parameter search for pruning...\")\n",
    "    for name, module in model_to_prune.named_modules():\n",
    "         if isinstance(module, LoraLayer):\n",
    "             print(f\"Found LoraLayer: {name}\")\n",
    "             for key in ['lora_A', 'lora_B']:\n",
    "                if hasattr(module, key):\n",
    "                    sub_module_dict = getattr(module, key)\n",
    "                    if isinstance(sub_module_dict, torch.nn.ModuleDict):\n",
    "                         for adapter_name, sub_module in sub_module_dict.items():\n",
    "                             if hasattr(sub_module, 'weight'):\n",
    "                                print(f\"   Found weight in {key}.{adapter_name}. Adding.\")\n",
    "                                parameters_to_prune.append((sub_module, 'weight'))\n",
    "                                target_modules.add(sub_module)\n",
    "                    elif isinstance(sub_module_dict, torch.nn.Module):\n",
    "                        if hasattr(sub_module_dict, 'weight'):\n",
    "                            print(f\"   Found weight directly in {key}. Adding.\")\n",
    "                            parameters_to_prune.append((sub_module_dict, 'weight'))\n",
    "                            target_modules.add(sub_module_dict)\n",
    "\n",
    "    if not parameters_to_prune:\n",
    "        print(\"Could not find any LoRA parameters to prune!\")\n",
    "        return 0.0\n",
    "    else:\n",
    "        print(f\"Identified {len(parameters_to_prune)} parameter tensors for pruning.\")\n",
    "        prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=amount)\n",
    "        print(\"Pruning mask applied. Making pruning permanent...\")\n",
    "        final_total_params = 0; final_zero_params = 0; pruned_module_count = 0\n",
    "        for module in target_modules:\n",
    "            is_currently_pruned = prune.is_pruned(module)\n",
    "            if is_currently_pruned:\n",
    "                 try:\n",
    "                     mask = getattr(module, 'weight_mask', None); orig_param = getattr(module, 'weight_orig', None)\n",
    "                     if mask is not None and orig_param is not None:\n",
    "                          param_element_count = orig_param.nelement(); param_zero_count = torch.sum(mask == 0).item()\n",
    "                          final_total_params += param_element_count; final_zero_params += param_zero_count\n",
    "                     elif hasattr(module, 'weight'):\n",
    "                          param = getattr(module, 'weight'); final_total_params += param.nelement(); final_zero_params += torch.sum(param == 0).item()\n",
    "                 except AttributeError:\n",
    "                       if hasattr(module, 'weight'):\n",
    "                           param = getattr(module, 'weight'); final_total_params += param.nelement(); final_zero_params += torch.sum(param == 0).item()\n",
    "                 prune.remove(module, 'weight'); pruned_module_count += 1\n",
    "            elif hasattr(module, 'weight'):\n",
    "                 param = getattr(module, 'weight'); final_total_params += param.nelement()\n",
    "        print(f\"Removed pruning buffer from {pruned_module_count} modules.\")\n",
    "        if final_total_params > 0:\n",
    "            final_sparsity = 100. * float(final_zero_params) / float(final_total_params)\n",
    "            print(f\"Pruning made permanent. Calculated sparsity: {final_sparsity:.2f}%\")\n",
    "            return final_sparsity\n",
    "        else:\n",
    "            print(\"Pruning made permanent (no parameters found or counted).\"); return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a62963e-cc02-406b-b2c2-f3f33b1f5bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tgs2126/py39_env/lib/python3.9/site-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.2364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2LMHeadModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=2304, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): Conv1D(nf=768, nx=768)\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D(nf=3072, nx=768)\n",
       "              (c_proj): Conv1D(nf=768, nx=3072)\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_texts_full = [t for t in dataset[\"train\"][\"text\"] if t.strip()]\n",
    "val_texts_full = [t for t in dataset[\"validation\"][\"text\"] if t.strip()]\n",
    "model_distilled_base = AutoModelForCausalLM.from_pretrained(\"./distilled_model\").to(device)\n",
    "for param in model_distilled_base.parameters(): param.requires_grad = False\n",
    "lora_r = 8\n",
    "lora_alpha = 32\n",
    "lora_target_modules = [\"c_attn\"]\n",
    "baseline_lr = 5e-5\n",
    "lora_lr = 1e-4\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "r=lora_r, lora_alpha=lora_alpha, target_modules=lora_target_modules,\n",
    "lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "lora_model_distilled = get_peft_model(model_distilled_base, lora_cfg)\n",
    "lora_model_distilled.print_trainable_parameters()\n",
    "lora_model_distilled.train()\n",
    "optim = torch.optim.AdamW(lora_model_distilled.parameters(), lr=1e-3)\n",
    "\n",
    "tmp_inputs = tokenizer(\n",
    "    [\"Just a short dummy batch.\"], return_tensors=\"pt\"\n",
    ").to(device)\n",
    "loss = lora_model_distilled(**tmp_inputs,\n",
    "                            labels=tmp_inputs.input_ids).loss\n",
    "loss.backward(); optim.step(); optim.zero_grad()\n",
    "lora_model_distilled.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea4dc85-7d15-4cbe-9745-65b68c1b4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_pruning_ratio(\n",
    "    base_model,\n",
    "    tokenizer,\n",
    "    val_texts,\n",
    "    device,\n",
    "    candidate_amounts = np.arange(0.0, 1.0, 0.1),   \n",
    "    quality_budget = 1.0,                            \n",
    "    quick_tokens   = 1000,                          \n",
    "    batch_size     = 16,\n",
    "    max_length     = 128\n",
    "):\n",
    "    \"\"\"Return pruning ratio that gives best memory win while staying within\n",
    "       `quality_budget` PPL increase wrt the un-pruned baseline.\n",
    "    \"\"\"\n",
    "    # 1) compute baseline PPL once\n",
    "    baseline_ppl = compute_perplexity(\n",
    "        base_model, tokenizer,\n",
    "        val_texts[:quick_tokens], device,\n",
    "        batch_size=batch_size, max_length=max_length\n",
    "    )\n",
    "    print(f\"[Sweep] Baseline (0 %): PPL={baseline_ppl:.2f}\")\n",
    "\n",
    "    scores = OrderedDict()\n",
    "    for amt in candidate_amounts[1:]:     \n",
    "        model_copy = copy.deepcopy(base_model).to(device)\n",
    "        apply_pruning(model_copy, amt)\n",
    "\n",
    "        ppl = compute_perplexity(\n",
    "            model_copy, tokenizer,\n",
    "            val_texts[:quick_tokens], device,\n",
    "            batch_size=batch_size, max_length=max_length\n",
    "        )\n",
    "        delta = ppl - baseline_ppl\n",
    "        scores[amt] = (ppl, delta)\n",
    "\n",
    "        print(f\"[Sweep] {int(amt*100):>2}% sparsity → \"\n",
    "                    f\"PPL={ppl:.2f} (Δ {delta:+.2f})\")\n",
    "\n",
    "        del model_copy\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # 2) choose the highest sparsity that meets quality budget\n",
    "    feasible = [a for a,(ppl,delta) in scores.items() if delta <= quality_budget]\n",
    "    if not feasible:\n",
    "        warnings.warn(\"No candidate met the quality budget; falling back to 0.0\")\n",
    "        return 0.0\n",
    "\n",
    "    best_amount = max(feasible)\n",
    "    print(f\"[Sweep] Selected pruning ratio = {best_amount:.2f} \"\n",
    "                f\"({int(best_amount*100)} %)\")\n",
    "    return best_amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e5a3d42-542e-451e-8259-17a61aec3990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sweep] Baseline ( 0 %) PPL = 1114.25\n",
      "Starting parameter search for pruning...\n",
      "Found LoraLayer: base_model.model.transformer.h.0.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.1.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.2.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.3.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.4.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.5.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.6.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.7.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.8.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.9.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.10.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.11.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Identified 24 parameter tensors for pruning.\n",
      "Pruning mask applied. Making pruning permanent...\n",
      "Removed pruning buffer from 24 modules.\n",
      "Pruning made permanent. Calculated sparsity: 10.00%\n",
      "[Sweep] 10 % sparsity → PPL=1114.23 (∆ -0.02)\n",
      "Starting parameter search for pruning...\n",
      "Found LoraLayer: base_model.model.transformer.h.0.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.1.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.2.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.3.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.4.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.5.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.6.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.7.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.8.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.9.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.10.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.11.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Identified 24 parameter tensors for pruning.\n",
      "Pruning mask applied. Making pruning permanent...\n",
      "Removed pruning buffer from 24 modules.\n",
      "Pruning made permanent. Calculated sparsity: 20.00%\n",
      "[Sweep] 20 % sparsity → PPL=1114.27 (∆ +0.02)\n",
      "Starting parameter search for pruning...\n",
      "Found LoraLayer: base_model.model.transformer.h.0.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.1.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.2.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.3.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.4.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.5.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.6.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.7.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.8.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.9.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.10.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.11.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Identified 24 parameter tensors for pruning.\n",
      "Pruning mask applied. Making pruning permanent...\n",
      "Removed pruning buffer from 24 modules.\n",
      "Pruning made permanent. Calculated sparsity: 30.00%\n",
      "[Sweep] 30 % sparsity → PPL=1114.26 (∆ +0.01)\n",
      "Starting parameter search for pruning...\n",
      "Found LoraLayer: base_model.model.transformer.h.0.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.1.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.2.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.3.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.4.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.5.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.6.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.7.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.8.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.9.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.10.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.11.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Identified 24 parameter tensors for pruning.\n",
      "Pruning mask applied. Making pruning permanent...\n",
      "Removed pruning buffer from 24 modules.\n",
      "Pruning made permanent. Calculated sparsity: 40.00%\n",
      "[Sweep] 40 % sparsity → PPL=1114.29 (∆ +0.04)\n",
      "Starting parameter search for pruning...\n",
      "Found LoraLayer: base_model.model.transformer.h.0.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.1.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.2.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.3.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.4.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.5.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.6.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.7.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.8.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.9.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.10.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.11.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Identified 24 parameter tensors for pruning.\n",
      "Pruning mask applied. Making pruning permanent...\n",
      "Removed pruning buffer from 24 modules.\n",
      "Pruning made permanent. Calculated sparsity: 50.00%\n",
      "[Sweep] 50 % sparsity → PPL=1114.36 (∆ +0.11)\n",
      "Starting parameter search for pruning...\n",
      "Found LoraLayer: base_model.model.transformer.h.0.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.1.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.2.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.3.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.4.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.5.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.6.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.7.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.8.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.9.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.10.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.11.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Identified 24 parameter tensors for pruning.\n",
      "Pruning mask applied. Making pruning permanent...\n",
      "Removed pruning buffer from 24 modules.\n",
      "Pruning made permanent. Calculated sparsity: 60.00%\n",
      "[Sweep] 60 % sparsity → PPL=1114.36 (∆ +0.11)\n",
      "Starting parameter search for pruning...\n",
      "Found LoraLayer: base_model.model.transformer.h.0.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.1.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.2.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.3.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.4.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.5.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.6.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.7.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.8.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.9.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.10.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.11.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Identified 24 parameter tensors for pruning.\n",
      "Pruning mask applied. Making pruning permanent...\n",
      "Removed pruning buffer from 24 modules.\n",
      "Pruning made permanent. Calculated sparsity: 70.00%\n",
      "[Sweep] 70 % sparsity → PPL=1114.02 (∆ -0.23)\n",
      "Starting parameter search for pruning...\n",
      "Found LoraLayer: base_model.model.transformer.h.0.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.1.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.2.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.3.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.4.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.5.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.6.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.7.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.8.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.9.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.10.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Found LoraLayer: base_model.model.transformer.h.11.attn.c_attn\n",
      "   Found weight in lora_A.default. Adding.\n",
      "   Found weight in lora_B.default. Adding.\n",
      "Identified 24 parameter tensors for pruning.\n",
      "Pruning mask applied. Making pruning permanent...\n",
      "Removed pruning buffer from 24 modules.\n",
      "Pruning made permanent. Calculated sparsity: 80.00%\n",
      "[Sweep] 80 % sparsity → PPL=1113.51 (∆ -0.73)\n",
      "[Sweep] Selected pruning ratio = 80 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using pruning_amount = 0.80\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import warnings, math, copy, torch\n",
    "\n",
    "def pick_pruning_ratio(\n",
    "    base_model,\n",
    "    tokenizer,\n",
    "    val_texts,\n",
    "    device,\n",
    "    candidate_amounts=np.arange(0.0, 0.9, 0.1),  \n",
    "    quality_budget=1.0,                           # tolerate +1 PPL\n",
    "    quick_tokens=1000,\n",
    "    batch_size=16,\n",
    "    max_length=128,\n",
    "    plot=True                                    \n",
    "):\n",
    "    \"\"\"\n",
    "    Sweep over pruning ratios and pick the highest sparsity whose\n",
    "    ∆PPL ≤ `quality_budget`.  If `plot` is True, draw a PPL-vs-sparsity\n",
    "    chart and mark the selected elbow point.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    best_amount : float\n",
    "        The selected pruning ratio (e.g. 0.8 for 80 %).\n",
    "    sweep_data  : OrderedDict[float, float]\n",
    "        Mapping sparsity → PPL for every candidate tested.\n",
    "    \"\"\"\n",
    "\n",
    "    #  baseline \n",
    "    baseline_ppl = compute_perplexity(\n",
    "        base_model, tokenizer,\n",
    "        val_texts[:quick_tokens], device,\n",
    "        batch_size=batch_size, max_length=max_length\n",
    "    )\n",
    "    print(f\"[Sweep] Baseline ( 0 %) PPL = {baseline_ppl:.2f}\")\n",
    "\n",
    "    sweep_data = OrderedDict({0.0: baseline_ppl})\n",
    "    for amt in candidate_amounts[1:]:\n",
    "        model_copy = copy.deepcopy(base_model).to(device)\n",
    "        apply_pruning(model_copy, amt)\n",
    "\n",
    "        ppl = compute_perplexity(\n",
    "            model_copy, tokenizer,\n",
    "            val_texts[:quick_tokens], device,\n",
    "            batch_size=batch_size, max_length=max_length\n",
    "        )\n",
    "        sweep_data[amt] = ppl\n",
    "        print(f\"[Sweep] {int(amt*100):2d} % sparsity → PPL={ppl:.2f} \"\n",
    "              f\"(∆ {ppl-baseline_ppl:+.2f})\")\n",
    "\n",
    "        del model_copy\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    #  choose ratio \n",
    "    feasible = [a for a,ppl in sweep_data.items() if ppl-baseline_ppl <= quality_budget]\n",
    "    if not feasible:\n",
    "        warnings.warn(\"No candidate met the quality budget; falling back to 0 %.\")\n",
    "        best_amount = 0.0\n",
    "    else:\n",
    "        best_amount = max(feasible)\n",
    "\n",
    "    print(f\"[Sweep] Selected pruning ratio = {int(best_amount*100)} %\")\n",
    "\n",
    "    #  optional plot \n",
    "    if plot:\n",
    "        sparsities = 100*np.array(list(sweep_data.keys()))\n",
    "        ppls       = np.array(list(sweep_data.values()))\n",
    "\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(sparsities, ppls, marker='o')\n",
    "        plt.axvline(100*best_amount, color='r', linestyle='--', label=f\"Chosen {int(best_amount*100)} %\")\n",
    "        plt.title(\"Perplexity vs. Pruning Ratio\")\n",
    "        plt.xlabel(\"Pruned Parameters (%)\")\n",
    "        plt.ylabel(\"Validation PPL\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return best_amount, sweep_data\n",
    "\n",
    "\n",
    "#  usage \n",
    "pruning_amount, sweep = pick_pruning_ratio(\n",
    "    lora_model_distilled,\n",
    "    tokenizer,\n",
    "    val_texts_full,\n",
    "    device=device,\n",
    "    candidate_amounts=np.arange(0.0, 0.81, 0.1),\n",
    "    quality_budget=1.0,\n",
    "    quick_tokens=1000,\n",
    "    plot=True          \n",
    ")\n",
    "\n",
    "print(f\"\\nUsing pruning_amount = {pruning_amount:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (benim)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
