{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accf3ed2-c24c-42fe-961e-a4d4a9ce844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Config, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import platform\n",
    "import time\n",
    "import wandb \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d9b54d-f81e-47c8-9d35-6b60b2713781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.9\n",
      "PyTorch version: 2.3.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU model: Tesla T4\n",
      "Number of GPUs: 1\n",
      "Available GPU memory: 15.64 GB\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU model: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Warning: FlashAttention requires CUDA GPU support. CPU execution will not work.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06738290-211d-4d46-9ace-049a102bf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class GPT2FlashBenchmark:\n",
    "    def __init__(self, model_name=\"gpt2\", batch_size=16, max_length=2048):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        self.max_length = max_length\n",
    "        logger.info(f\"Loading {model_name} model and tokenizer with flash attention enabled...\")\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token    \n",
    "        config = GPT2Config.from_pretrained(model_name)\n",
    "        config.use_flash_attention = True       \n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_name, config=config).to(self.device)\n",
    "        logger.info(\"Loading dataset...\")\n",
    "        self.dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\")\n",
    "        \n",
    "    def benchmark_training(self, num_batches=100):\n",
    "        \"\"\"Benchmark training performance\"\"\"\n",
    "        logger.info(\"Starting training benchmark...\")\n",
    "        self.model.train()\n",
    "        \n",
    "        # Prepare data\n",
    "        train_data = self.dataset[\"train\"][\"text\"]\n",
    "        train_data = [text for text in train_data if len(text.strip()) > 0]  \n",
    "        \n",
    "        metrics = {\n",
    "            \"training_time\": [],\n",
    "            \"memory_usage\": [],\n",
    "            \"throughput\": [],\n",
    "            \"loss\": [],\n",
    "            \"perplexity\": []\n",
    "        }\n",
    "        \n",
    "        for i in tqdm(range(num_batches)):\n",
    "            batch_texts = train_data[i*self.batch_size:(i+1)*self.batch_size]\n",
    "            if not batch_texts:  \n",
    "                continue\n",
    "                \n",
    "            inputs = self.tokenizer(batch_texts, \n",
    "                                    padding=True, \n",
    "                                    truncation=True, \n",
    "                                    max_length=self.max_length,\n",
    "                                    return_tensors=\"pt\").to(self.device)\n",
    "            \n",
    "            # Start timing\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Calculate perplexity\n",
    "            perplexity = torch.exp(loss)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Record metrics\n",
    "            batch_time = time.time() - start_time\n",
    "            memory_usage = torch.cuda.memory_allocated() / 1024**2  # MB\n",
    "            \n",
    "            \"\"\"\n",
    "            wandb.log({\n",
    "                \"batch_training_time\": batch_time,\n",
    "                \"batch_memory_usage\": memory_usage,\n",
    "                \"batch_throughput\": self.batch_size / batch_time,\n",
    "                \"batch_loss\": loss.item(),\n",
    "                \"batch_perplexity\": perplexity.item()\n",
    "            })\n",
    "            \"\"\"\n",
    "            \n",
    "            metrics[\"training_time\"].append(batch_time)\n",
    "            metrics[\"memory_usage\"].append(memory_usage)\n",
    "            metrics[\"throughput\"].append(self.batch_size / batch_time)\n",
    "            metrics[\"loss\"].append(loss.item())\n",
    "            metrics[\"perplexity\"].append(perplexity.item())\n",
    "            self.model.zero_grad()\n",
    "            \n",
    "        return metrics\n",
    "    \n",
    "    def benchmark_inference(self, num_batches=100):\n",
    "        \"\"\"Benchmark inference performance\"\"\"\n",
    "        logger.info(\"Starting inference benchmark...\")\n",
    "        self.model.eval()\n",
    "    \n",
    "        test_data = self.dataset[\"test\"][\"text\"]\n",
    "        test_data = [text for text in test_data if len(text.strip()) > 0]  \n",
    "        \n",
    "        metrics = {\n",
    "            \"inference_time\": [],\n",
    "            \"memory_usage\": [],\n",
    "            \"throughput\": [],\n",
    "            \"perplexity\": []\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(num_batches)):\n",
    "                batch_texts = test_data[i*self.batch_size:(i+1)*self.batch_size]\n",
    "                if not batch_texts: \n",
    "                    continue\n",
    "                    \n",
    "                inputs = self.tokenizer(batch_texts, \n",
    "                                        padding=True, \n",
    "                                        truncation=True, \n",
    "                                        max_length=self.max_length,\n",
    "                                        return_tensors=\"pt\").to(self.device)\n",
    "                \n",
    "                # Start timing\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(**inputs, labels=inputs[\"input_ids\"])\n",
    "                loss = outputs.loss\n",
    "                perplexity = torch.exp(loss)\n",
    "                \n",
    "                # Record metrics\n",
    "                batch_time = time.time() - start_time\n",
    "                memory_usage = torch.cuda.memory_allocated() / 1024**2  # MB\n",
    "                \n",
    "\n",
    "                \"\"\"\n",
    "                wandb.log({\n",
    "                    \"batch_inference_time\": batch_time,\n",
    "                    \"batch_inference_memory\": memory_usage,\n",
    "                    \"batch_inference_throughput\": self.batch_size / batch_time,\n",
    "                    \"batch_inference_perplexity\": perplexity.item()\n",
    "                })\n",
    "                \"\"\"\n",
    "                \n",
    "                metrics[\"inference_time\"].append(batch_time)\n",
    "                metrics[\"memory_usage\"].append(memory_usage)\n",
    "                metrics[\"throughput\"].append(self.batch_size / batch_time)\n",
    "                metrics[\"perplexity\"].append(perplexity.item())\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def run_benchmarks(self, num_batches=100):\n",
    "        \"\"\"Run all benchmarks and log results\"\"\"\n",
    "        logger.info(\"Starting comprehensive benchmark for flash attention model...\")\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        wandb.init(project=\"gpt2-benchmark-flash\", \n",
    "                   config={\n",
    "                       \"model_name\": self.model_name,\n",
    "                       \"batch_size\": self.batch_size,\n",
    "                       \"max_length\": self.max_length\n",
    "                   })\n",
    "        \"\"\"\n",
    "        \n",
    "        training_metrics = self.benchmark_training(num_batches=num_batches)\n",
    "        inference_metrics = self.benchmark_inference(num_batches=num_batches)\n",
    "        \n",
    "        results = {\n",
    "            \"training\": {\n",
    "                \"avg_time\": np.mean(training_metrics[\"training_time\"]),\n",
    "                \"avg_memory\": np.mean(training_metrics[\"memory_usage\"]),\n",
    "                \"avg_throughput\": np.mean(training_metrics[\"throughput\"]),\n",
    "                \"avg_loss\": np.mean(training_metrics[\"loss\"]),\n",
    "                \"avg_perplexity\": np.mean(training_metrics[\"perplexity\"]),\n",
    "                \"std_time\": np.std(training_metrics[\"training_time\"]),\n",
    "                \"std_memory\": np.std(training_metrics[\"memory_usage\"]),\n",
    "                \"std_throughput\": np.std(training_metrics[\"throughput\"]),\n",
    "                \"std_loss\": np.std(training_metrics[\"loss\"]),\n",
    "                \"std_perplexity\": np.std(training_metrics[\"perplexity\"])\n",
    "            },\n",
    "            \"inference\": {\n",
    "                \"avg_time\": np.mean(inference_metrics[\"inference_time\"]),\n",
    "                \"avg_memory\": np.mean(inference_metrics[\"memory_usage\"]),\n",
    "                \"avg_throughput\": np.mean(inference_metrics[\"throughput\"]),\n",
    "                \"avg_perplexity\": np.mean(inference_metrics[\"perplexity\"]),\n",
    "                \"std_time\": np.std(inference_metrics[\"inference_time\"]),\n",
    "                \"std_memory\": np.std(inference_metrics[\"memory_usage\"]),\n",
    "                \"std_throughput\": np.std(inference_metrics[\"throughput\"]),\n",
    "                \"std_perplexity\": np.std(inference_metrics[\"perplexity\"])\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        \"\"\"\n",
    "        wandb.log(results)\n",
    "        logger.info(\"Benchmark Results:\")\n",
    "        \"\"\"\n",
    "        \n",
    "        logger.info(\"\\nBenchmark Results (Flash Attention Model):\")\n",
    "        logger.info(\"Training:\")\n",
    "        logger.info(f\"Average time per batch: {results['training']['avg_time']:.4f} ± {results['training']['std_time']:.4f} seconds\")\n",
    "        logger.info(f\"Average memory usage: {results['training']['avg_memory']:.2f} ± {results['training']['std_memory']:.2f} MB\")\n",
    "        logger.info(f\"Average throughput: {results['training']['avg_throughput']:.2f} ± {results['training']['std_throughput']:.2f} samples/second\")\n",
    "        logger.info(f\"Average loss: {results['training']['avg_loss']:.4f} ± {results['training']['std_loss']:.4f}\")\n",
    "        logger.info(f\"Average perplexity: {results['training']['avg_perplexity']:.4f} ± {results['training']['std_perplexity']:.4f}\")\n",
    "        \n",
    "        logger.info(\"\\nInference:\")\n",
    "        logger.info(f\"Average time per batch: {results['inference']['avg_time']:.4f} ± {results['inference']['std_time']:.4f} seconds\")\n",
    "        logger.info(f\"Average memory usage: {results['inference']['avg_memory']:.2f} ± {results['inference']['std_memory']:.2f} MB\")\n",
    "        logger.info(f\"Average throughput: {results['inference']['avg_throughput']:.2f} ± {results['inference']['std_throughput']:.2f} samples/second\")\n",
    "        logger.info(f\"Average perplexity: {results['inference']['avg_perplexity']:.4f} ± {results['inference']['std_perplexity']:.4f}\")\n",
    "        \n",
    "        \"\"\"\n",
    "        wandb.finish()\n",
    "        \"\"\"\n",
    "        return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36e5b9-1681-47f3-b1af-0ef059e80647",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = GPT2FlashBenchmark()\n",
    "results = benchmark.run_benchmarks(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068df81-a115-498c-93bf-b2483675c54a",
   "metadata": {},
   "source": [
    "# Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20145e8-62ce-4afb-a92b-010c352f8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed26916c-f3d9-43ec-9d26-e93d1c8b35b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2153d4-4005-40d9-850c-cfab6e1555d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GPT-2 base model and tokenizer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  \n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "print(\"Loaded GPT-2 base model and tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a78591-48a2-4849-9bfb-099882608a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All GPT-2 parameters frozen because we'll only train LoRA adapters\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"All GPT-2 parameters frozen because we'll only train LoRA adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d9bcea-ddad-49b7-a6e9-44cfedbee483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA adapters injected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tgs2126/py39_env/lib/python3.9/site-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LoRA adapters\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                        \n",
    "    lora_alpha=32,             \n",
    "    target_modules=[\"c_attn\"],  \n",
    "    lora_dropout=0.05,          \n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(\"LoRA adapters injected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c804b4f-fb36-4de2-a0e4-61725309cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke test passed! Loss = 4.8964\n"
     ]
    }
   ],
   "source": [
    "# Example testing\n",
    "example_texts = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\"\n",
    "]\n",
    "inputs = tokenizer(\n",
    "    example_texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=32,\n",
    "    return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "outputs = model(**inputs, labels=inputs.input_ids)\n",
    "loss = outputs.loss\n",
    "loss.backward()   \n",
    "\n",
    "print(f\"Smoke test passed! Loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92faf12-b585-4af5-b5d9-e245e7e30c14",
   "metadata": {},
   "source": [
    "# Lora Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cb58fa4-3d71-4501-8523-da7e7d6143e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 02:18:01,175 - INFO - Loading wikitext-2 dataset...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import logging\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Loading wikitext-2 dataset...\")\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d688d8-8c65-4978-ac6e-eb816f8f052c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 02:18:06,307 - INFO - Using device: cuda\n",
      "2025-05-03 02:18:07,187 - INFO - Loaded & froze base GPT-2\n",
      "2025-05-03 02:18:07,209 - INFO - Injected LoRA adapters\n"
     ]
    }
   ],
   "source": [
    "# LoRA adapters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "base_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(base_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = GPT2LMHeadModel.from_pretrained(base_name).to(device)\n",
    "for p in base_model.parameters(): \n",
    "    p.requires_grad = False\n",
    "logger.info(\"Loaded & froze base GPT-2\")\n",
    "\n",
    "# LoRA\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"c_attn\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "logger.info(\"Injected LoRA adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89cb7194-b54b-46b2-bfd2-976a593df7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_loRA(model, tokenizer, dataset, batch_size, max_length=128,\n",
    "                   num_train_batches=100, num_infer_batches=100):\n",
    "    import time, torch, numpy as np\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    train_texts = [t for t in dataset[\"train\"][\"text\"] if t.strip()]\n",
    "    test_texts  = [t for t in dataset[\"test\"][\"text\"]  if t.strip()]\n",
    "\n",
    "    # ---- TRAINING BENCHMARK ----\n",
    "    model.train()\n",
    "    train_times, train_mems = [], []\n",
    "    train_thrpts, train_losses, train_perps = [], [], []\n",
    "\n",
    "    for i in range(num_train_batches):\n",
    "        batch = train_texts[i*batch_size:(i+1)*batch_size]\n",
    "        if not batch:\n",
    "            break\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        start = time.time()\n",
    "        outputs = model(**inputs, labels=inputs.input_ids)\n",
    "        loss    = outputs.loss\n",
    "        perp    = torch.exp(loss).item()\n",
    "        loss.backward()\n",
    "        elapsed = time.time() - start\n",
    "        mem     = torch.cuda.memory_allocated(device) / 1024**2\n",
    "\n",
    "        train_times .append(elapsed)\n",
    "        train_mems  .append(mem)\n",
    "        train_thrpts.append(batch_size / elapsed)\n",
    "        train_losses.append(loss.item())\n",
    "        train_perps .append(perp)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "    train_stats = {\n",
    "        \"time\":       (np.mean(train_times),   np.std(train_times)),\n",
    "        \"memory\":     (np.mean(train_mems),    np.std(train_mems)),\n",
    "        \"throughput\": (np.mean(train_thrpts),  np.std(train_thrpts)),\n",
    "        \"loss\":       (np.mean(train_losses),  np.std(train_losses)),\n",
    "        \"perplexity\": (np.mean(train_perps),   np.std(train_perps))\n",
    "    }\n",
    "\n",
    "    # ---- INFERENCE BENCHMARK ----\n",
    "    model.eval()\n",
    "    infer_times, infer_mems = [], []\n",
    "    infer_thrpts, infer_perps = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_infer_batches):\n",
    "            batch = test_texts[i*batch_size:(i+1)*batch_size]\n",
    "            if not batch:\n",
    "                break\n",
    "\n",
    "            inputs = tokenizer(\n",
    "                batch,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            start = time.time()\n",
    "            outputs = model(**inputs, labels=inputs.input_ids)\n",
    "            loss    = outputs.loss\n",
    "            perp    = torch.exp(loss).item()\n",
    "            elapsed = time.time() - start\n",
    "            mem     = torch.cuda.memory_allocated(device) / 1024**2\n",
    "\n",
    "            infer_times .append(elapsed)\n",
    "            infer_mems  .append(mem)\n",
    "            infer_thrpts.append(batch_size / elapsed)\n",
    "            infer_perps .append(perp)\n",
    "\n",
    "    infer_stats = {\n",
    "        \"time\":       (np.mean(infer_times),   np.std(infer_times)),\n",
    "        \"memory\":     (np.mean(infer_mems),    np.std(infer_mems)),\n",
    "        \"throughput\": (np.mean(infer_thrpts),  np.std(infer_thrpts)),\n",
    "        \"perplexity\": (np.mean(infer_perps),   np.std(infer_perps))\n",
    "    }\n",
    "\n",
    "    return train_stats, infer_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6385d9db-d260-4025-b839-f2e90438b428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 02:18:07,242 - INFO - \n",
      "Running benchmark for LoRA model with batch_size=8, max_length=128\n",
      "2025-05-03 02:18:07,243 - INFO - Configuration:\n",
      "2025-05-03 02:18:07,244 - INFO -   • Model:  LoRA on GPT-2\n",
      "2025-05-03 02:18:07,245 - INFO -   • Batch size:   8\n",
      "2025-05-03 02:18:07,245 - INFO -   • Max length:   128\n",
      "2025-05-03 02:18:33,757 - INFO - \n",
      "Training:\n",
      "2025-05-03 02:18:33,758 - INFO -   Average time per batch:    0.0864 ± 0.0216 seconds\n",
      "2025-05-03 02:18:33,759 - INFO -   Average memory usage:      786.52 ± 80.44 MB\n",
      "2025-05-03 02:18:33,759 - INFO -   Average throughput:        105.52 ± 54.76 samples/second\n",
      "2025-05-03 02:18:33,760 - INFO -   Average loss:              6.6862 ± 0.9764\n",
      "2025-05-03 02:18:33,760 - INFO -   Average perplexity:        1305.5410 ± 1469.3894\n",
      "2025-05-03 02:18:33,761 - INFO - \n",
      "Inference:\n",
      "2025-05-03 02:18:33,762 - INFO -   Average time per batch:    0.0770 ± 0.0187 seconds\n",
      "2025-05-03 02:18:33,762 - INFO -   Average memory usage:      791.70 ± 73.05 MB\n",
      "2025-05-03 02:18:33,763 - INFO -   Average throughput:        130.42 ± 112.05 samples/second\n",
      "2025-05-03 02:18:33,763 - INFO -   Average perplexity:        1971.5900 ± 3014.9935\n",
      "2025-05-03 02:18:33,764 - INFO - \n",
      "Running benchmark for LoRA model with batch_size=16, max_length=128\n",
      "2025-05-03 02:18:33,764 - INFO - Configuration:\n",
      "2025-05-03 02:18:33,765 - INFO -   • Model:  LoRA on GPT-2\n",
      "2025-05-03 02:18:33,765 - INFO -   • Batch size:   16\n",
      "2025-05-03 02:18:33,766 - INFO -   • Max length:   128\n",
      "2025-05-03 02:19:28,881 - INFO - \n",
      "Training:\n",
      "2025-05-03 02:19:28,882 - INFO -   Average time per batch:    0.1831 ± 0.0288 seconds\n",
      "2025-05-03 02:19:28,882 - INFO -   Average memory usage:      1103.06 ± 97.34 MB\n",
      "2025-05-03 02:19:28,883 - INFO -   Average throughput:        94.94 ± 49.34 samples/second\n",
      "2025-05-03 02:19:28,883 - INFO -   Average loss:              6.5580 ± 0.9085\n",
      "2025-05-03 02:19:28,884 - INFO -   Average perplexity:        1171.6664 ± 1624.2727\n",
      "2025-05-03 02:19:28,884 - INFO - \n",
      "Inference:\n",
      "2025-05-03 02:19:28,885 - INFO -   Average time per batch:    0.1546 ± 0.0371 seconds\n",
      "2025-05-03 02:19:28,885 - INFO -   Average memory usage:      1077.34 ± 138.87 MB\n",
      "2025-05-03 02:19:28,886 - INFO -   Average throughput:        131.57 ± 124.47 samples/second\n",
      "2025-05-03 02:19:28,886 - INFO -   Average perplexity:        3126.3712 ± 6117.7730\n",
      "2025-05-03 02:19:28,887 - INFO - \n",
      "Running benchmark for LoRA model with batch_size=32, max_length=128\n",
      "2025-05-03 02:19:28,887 - INFO - Configuration:\n",
      "2025-05-03 02:19:28,888 - INFO -   • Model:  LoRA on GPT-2\n",
      "2025-05-03 02:19:28,889 - INFO -   • Batch size:   32\n",
      "2025-05-03 02:19:28,889 - INFO -   • Max length:   128\n",
      "2025-05-03 02:21:20,961 - INFO - \n",
      "Training:\n",
      "2025-05-03 02:21:20,962 - INFO -   Average time per batch:    0.3507 ± 0.0341 seconds\n",
      "2025-05-03 02:21:20,963 - INFO -   Average memory usage:      1714.12 ± 121.17 MB\n",
      "2025-05-03 02:21:20,964 - INFO -   Average throughput:        94.35 ± 34.28 samples/second\n",
      "2025-05-03 02:21:20,964 - INFO -   Average loss:              6.7631 ± 0.9009\n",
      "2025-05-03 02:21:20,964 - INFO -   Average perplexity:        1453.7507 ± 2259.5630\n",
      "2025-05-03 02:21:20,965 - INFO - \n",
      "Inference:\n",
      "2025-05-03 02:21:20,966 - INFO -   Average time per batch:    0.3240 ± 0.0498 seconds\n",
      "2025-05-03 02:21:20,966 - INFO -   Average memory usage:      1693.53 ± 182.84 MB\n",
      "2025-05-03 02:21:20,967 - INFO -   Average throughput:        106.97 ± 54.22 samples/second\n",
      "2025-05-03 02:21:20,968 - INFO -   Average perplexity:        3173.5357 ± 6510.7555\n"
     ]
    }
   ],
   "source": [
    "# Running benchmarks\n",
    "max_length = 128\n",
    "\n",
    "for bs in [8, 16, 32]:\n",
    "    logger.info(f\"\\nRunning benchmark for LoRA model with batch_size={bs}, max_length={max_length}\")\n",
    "    logger.info(\"Configuration:\")\n",
    "    logger.info(f\"  • Model:  LoRA on GPT-2\")\n",
    "    logger.info(f\"  • Batch size:   {bs}\")\n",
    "    logger.info(f\"  • Max length:   {max_length}\")\n",
    "    \n",
    "    train_stats, infer_stats = benchmark_loRA(\n",
    "        model, tokenizer, dataset,\n",
    "        batch_size=bs, max_length=max_length,\n",
    "        num_train_batches=100, num_infer_batches=100\n",
    "    )\n",
    "\n",
    "    # Training results\n",
    "    t = train_stats\n",
    "    logger.info(\"\\nTraining:\")\n",
    "    logger.info(f\"  Average time per batch:    {t['time'][0]:.4f} ± {t['time'][1]:.4f} seconds\")\n",
    "    logger.info(f\"  Average memory usage:      {t['memory'][0]:.2f} ± {t['memory'][1]:.2f} MB\")\n",
    "    logger.info(f\"  Average throughput:        {t['throughput'][0]:.2f} ± {t['throughput'][1]:.2f} samples/second\")\n",
    "    logger.info(f\"  Average loss:              {t['loss'][0]:.4f} ± {t['loss'][1]:.4f}\")\n",
    "    logger.info(f\"  Average perplexity:        {t['perplexity'][0]:.4f} ± {t['perplexity'][1]:.4f}\")\n",
    "    \n",
    "    # Inference results\n",
    "    i = infer_stats\n",
    "    logger.info(\"\\nInference:\")\n",
    "    logger.info(f\"  Average time per batch:    {i['time'][0]:.4f} ± {i['time'][1]:.4f} seconds\")\n",
    "    logger.info(f\"  Average memory usage:      {i['memory'][0]:.2f} ± {i['memory'][1]:.2f} MB\")\n",
    "    logger.info(f\"  Average throughput:        {i['throughput'][0]:.2f} ± {i['throughput'][1]:.2f} samples/second\")\n",
    "    logger.info(f\"  Average perplexity:        {i['perplexity'][0]:.4f} ± {i['perplexity'][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f361e43-e868-4c33-8a01-2b6f305d31f9",
   "metadata": {},
   "source": [
    "# Lora apples-to-apples bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca32decf-8152-4e32-b9c3-3c4a3a7438fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time, math, logging\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torch.optim import AdamW  \n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3ec7a2e-ee82-4c92-84c0-7b789169bfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 02:21:21,097 - INFO - Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "dataset   = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04ad6454-70a3-44c6-946e-59ec8b66f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def compute_perplexity(model, tokenizer, texts, device,\n",
    "                       batch_size=8, max_length=128):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch, padding=True, truncation=True,\n",
    "                               max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "            loss = model(**inputs, labels=inputs.input_ids).loss\n",
    "            losses.append(loss.item())\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    return math.exp(avg_loss)\n",
    "\n",
    "def train_until(model, tokenizer, dataset, target_ppl,\n",
    "                device, lr=5e-5, batch_size=8, max_length=128,\n",
    "                eval_every=500):\n",
    "    optimizer   = AdamW(model.parameters(), lr=lr)\n",
    "    train_texts = [t for t in dataset[\"train\"][\"text\"]      if t.strip()]\n",
    "    val_texts   = [t for t in dataset[\"validation\"][\"text\"] if t.strip()]\n",
    "\n",
    "    start_time = time.time()\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    step = 0\n",
    "\n",
    "    while True:\n",
    "        model.train()\n",
    "        for i in range(0, len(train_texts), batch_size):\n",
    "            batch  = train_texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch, padding=True, truncation=True,\n",
    "                               max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "\n",
    "            loss = model(**inputs, labels=inputs.input_ids).loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "            step += 1\n",
    "            if step % eval_every == 0:\n",
    "                val_ppl = compute_perplexity(model, tokenizer, val_texts, device,\n",
    "                                             batch_size=batch_size, max_length=max_length)\n",
    "                elapsed_h = (time.time() - start_time) / 3600\n",
    "                peak_mem  = torch.cuda.memory_allocated(device) / 1024**2\n",
    "                logger.info(f\"[step {step}] val_ppl={val_ppl:.2f} time={elapsed_h:.2f}h peak_mem={peak_mem:.1f}MB\")\n",
    "                if val_ppl <= target_ppl:\n",
    "                    total_h = (time.time() - start_time) / 3600\n",
    "                    final_mem = torch.cuda.memory_allocated(device) / 1024**2\n",
    "                    return {\n",
    "                        \"steps\":       step,\n",
    "                        \"total_hours\": total_h,\n",
    "                        \"peak_mem_mb\": final_mem,\n",
    "                        \"final_ppl\":   val_ppl\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c3408f5-0e96-4974-aa8b-fbc9a6f72144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 02:26:13,752 - INFO - [step 500] val_ppl=8.40 time=0.08h peak_mem=1952.4MB\n",
      "2025-05-03 02:26:13,759 - INFO - Baseline results: {'steps': 500, 'total_hours': 0.07995118220647177, 'peak_mem_mb': 1952.40234375, 'final_ppl': 8.398031046667038}\n"
     ]
    }
   ],
   "source": [
    "#Baseline full fine-tune benchmark\n",
    "baseline_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "for p in baseline_model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "baseline_res = train_until(\n",
    "    baseline_model, tokenizer, dataset, target_ppl=15,\n",
    "    device=device, lr=5e-5, batch_size=16, max_length=128,\n",
    "    eval_every=500\n",
    ")\n",
    "logger.info(f\"Baseline results: {baseline_res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "009cd7f7-72e8-4cb3-acac-c9cdbe20b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after baseline finishes\n",
    "del baseline_model  \n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c057b76b-66d4-410d-b26c-e69c683ad2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 02:26:13,919 - INFO - Using device: cuda\n",
      "2025-05-03 02:26:14,812 - INFO - Loaded GPT-2\n",
      "2025-05-03 02:26:14,834 - INFO - Injected LoRA adapters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.2364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 02:29:43,754 - INFO - [step 500] val_ppl=9.37 time=0.06h peak_mem=516.0MB\n",
      "2025-05-03 02:29:43,759 - INFO - LoRA results: {'steps': 500, 'total_hours': 0.05801610675123003, 'peak_mem_mb': 515.95166015625, 'final_ppl': 9.366225498020455}\n"
     ]
    }
   ],
   "source": [
    "# LoRA \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "base_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(base_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model = GPT2LMHeadModel.from_pretrained(base_name).to(device)\n",
    "logger.info(\"Loaded GPT-2\")\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"c_attn\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "logger.info(\"Injected LoRA adapters\")\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "lora_res = train_until(\n",
    "    model, tokenizer, dataset, target_ppl=15,\n",
    "    device=device, lr=1e-4, batch_size=16, max_length=128,\n",
    "    eval_every=500\n",
    ")\n",
    "logger.info(f\"LoRA results: {lora_res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4d2e2ab-d21f-453a-a63f-d696c0200633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([baseline_res, lora_res], index=[\"Baseline\", \"LoRA\"])\n",
    "df.rename(columns={\n",
    "    \"steps\":       \"Steps\",\n",
    "    \"total_hours\":\"Total Hours (h)\",\n",
    "    \"peak_mem_mb\":\"Peak GPU Mem (MB)\",\n",
    "    \"final_ppl\":  \"Final Val Perplexity\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31724b5c-c7f4-42b6-9a07-4dc9aa5eca28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Steps</th>\n",
       "      <th>Total Hours (h)</th>\n",
       "      <th>Peak GPU Mem (MB)</th>\n",
       "      <th>Final Val Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>500</td>\n",
       "      <td>0.079951</td>\n",
       "      <td>1952.402344</td>\n",
       "      <td>8.398031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA</th>\n",
       "      <td>500</td>\n",
       "      <td>0.058016</td>\n",
       "      <td>515.951660</td>\n",
       "      <td>9.366225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Steps  Total Hours (h)  Peak GPU Mem (MB)  Final Val Perplexity\n",
       "Baseline    500         0.079951        1952.402344              8.398031\n",
       "LoRA        500         0.058016         515.951660              9.366225"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb21532f-11bd-4264-9814-a47a4289475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA model & tokenizer saved to lora_gpt2_checkpoint\n"
     ]
    }
   ],
   "source": [
    "# Saving Lora model\n",
    "'''\n",
    "save_dir = \"lora_gpt2_checkpoint\"\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(f\"LoRA model & tokenizer saved to {save_dir}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327a8a52-460e-4d2e-aa47-d06dc4a128c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload\n",
    "'''\n",
    "save_dir = \"lora_gpt2_checkpoint\"\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from peft import PeftModel\n",
    "base = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tok  = GPT2Tokenizer.from_pretrained(save_dir)\n",
    "tok.pad_token = tok.eos_token\n",
    "model = PeftModel.from_pretrained(base, save_dir).to(device)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9014eccc-23db-40d7-b577-5d8aed98b259",
   "metadata": {},
   "source": [
    "# Unstructured Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a084eba-bbfc-467d-ad85-3a8d99b5e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import peft \n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0683414-7aa4-4d0f-b4ff-95426343aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b709d4-bb31-4794-836d-21f010c8569f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 21:49:32,415 - INFO - Starting global unstructured pruning with amount: 0.5\n",
      "2025-05-03 21:49:32,416 - INFO - Targeting LoRA A and LoRA B weights.\n"
     ]
    }
   ],
   "source": [
    "# Pruning Parameters \n",
    "pruning_amount = 0.5  # Prune 50% of the weights \n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.hasHandlers():\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "logger.info(f\"Starting global unstructured pruning with amount: {pruning_amount}\")\n",
    "logger.info(f\"Targeting LoRA A and LoRA B weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9d2529b-9896-4827-85a2-e2ba67368455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 21:49:32,715 - INFO - Identifying LoRA parameters for pruning...\n"
     ]
    }
   ],
   "source": [
    "# Identifying LoRA Parameters to Prune \n",
    "parameters_to_prune = []\n",
    "target_modules = []\n",
    "\n",
    "logger.info(\"Identifying LoRA parameters for pruning...\")\n",
    "for name, module in lora_model.named_modules():\n",
    "    if isinstance(module, peft.tuners.lora.Linear):\n",
    "        logger.debug(f\"Found LoRA linear layer: {name}\")\n",
    "        for param_name, param in module.named_parameters():\n",
    "            if 'lora_A' in param_name and 'weight' in param_name:\n",
    "                parameters_to_prune.append((module, 'weight')) # Prune the weight of lora_A\n",
    "                target_modules.append(module) \n",
    "                logger.debug(f\"  - Added '{param_name}' (accessed via 'weight' on module {type(module).__name__}) to pruning list.\")\n",
    "            elif 'lora_B' in param_name and 'weight' in param_name:\n",
    "                 pass # We will handle this below more robustly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65b04e05-43e6-4c11-a4cc-e482152ec76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 21:49:39,952 - INFO - Identified 24 parameter tensors to prune.\n",
      "2025-05-03 21:49:39,953 - INFO - Applying global unstructured pruning (L1 magnitude) with amount=0.5...\n",
      "2025-05-03 21:49:40,400 - INFO - Pruning mask applied.\n",
      "2025-05-03 21:49:40,470 - INFO - Sparsity after applying mask: 50.00%\n",
      "2025-05-03 21:49:40,471 - INFO - Making pruning permanent by removing masks and zeroing weights...\n",
      "2025-05-03 21:49:40,473 - INFO - Pruning made permanent.\n",
      "2025-05-03 21:49:40,475 - INFO - Final sparsity after mask removal: 50.00%\n",
      "2025-05-03 21:49:40,476 - INFO - Total LoRA parameters considered for pruning: 294912\n",
      "2025-05-03 21:49:40,476 - INFO - Total zeroed parameters in LoRA layers: 147456\n",
      "2025-05-03 21:49:40,477 - INFO - Pruning process complete. `lora_model` has been modified in-place.\n"
     ]
    }
   ],
   "source": [
    "# Refined approach to find correct parameter names for pruning within LoRA layers\n",
    "parameters_to_prune_refined = []\n",
    "target_modules_refined = []\n",
    "for name, module in lora_model.named_modules():\n",
    "     if isinstance(module, peft.tuners.lora.LoraLayer): \n",
    "         logger.debug(f\"Found LoRA layer: {name} of type {type(module)}\")\n",
    "         if hasattr(module, 'lora_A') and hasattr(module.lora_A, 'default'):\n",
    "             if hasattr(module.lora_A['default'], 'weight'):\n",
    "                 logger.debug(f\"  - Adding parameter 'lora_A.default.weight' from module {name}\")\n",
    "                 parameters_to_prune_refined.append((module.lora_A['default'], 'weight'))\n",
    "                 target_modules_refined.append(module.lora_A['default'])\n",
    "         if hasattr(module, 'lora_B') and hasattr(module.lora_B, 'default'): \n",
    "             if hasattr(module.lora_B['default'], 'weight'):\n",
    "                 logger.debug(f\"  - Adding parameter 'lora_B.default.weight' from module {name}\")\n",
    "                 parameters_to_prune_refined.append((module.lora_B['default'], 'weight'))\n",
    "                 target_modules_refined.append(module.lora_B['default'])\n",
    "\n",
    "\n",
    "if not parameters_to_prune_refined:\n",
    "    logger.warning(\"Could not find any LoRA A/B weights matching expected structure.\")\n",
    "    logger.warning(\"Please inspect your model's layers and parameter names.\")\n",
    "else:\n",
    "    logger.info(f\"Identified {len(parameters_to_prune_refined)} parameter tensors to prune.\")\n",
    "\n",
    "    # Global Unstructured Pruning\n",
    "    logger.info(f\"Applying global unstructured pruning (L1 magnitude) with amount={pruning_amount}...\")\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune_refined,\n",
    "        pruning_method=prune.L1Unstructured, # Prune weights with smallest L1 norm \n",
    "        amount=pruning_amount,\n",
    "    )\n",
    "    logger.info(\"Pruning mask applied.\")\n",
    "\n",
    "    # Verify Sparsity \n",
    "    def calculate_global_sparsity(parameters):\n",
    "        total_params = 0\n",
    "        zero_params = 0\n",
    "        for module, name in parameters:\n",
    "            param = getattr(module, name)\n",
    "            total_params += param.nelement()\n",
    "            zero_params += torch.sum(param == 0).item()\n",
    "        if total_params == 0:\n",
    "            return 0.0\n",
    "        sparsity = 100. * float(zero_params) / float(total_params)\n",
    "        return sparsity, zero_params, total_params\n",
    "\n",
    "    # Calculate sparsity *while the mask is active*\n",
    "    sparsity_before_remove, _, _ = calculate_global_sparsity(parameters_to_prune_refined)\n",
    "    logger.info(f\"Sparsity after applying mask: {sparsity_before_remove:.2f}%\")\n",
    "\n",
    "    # Make Pruning Permanent \n",
    "    logger.info(\"Making pruning permanent by removing masks and zeroing weights...\")\n",
    "    for module in target_modules_refined:\n",
    "         if prune.is_pruned(module):\n",
    "              prune.remove(module, 'weight') \n",
    "              logger.debug(f\"Removed pruning mask from parameter 'weight' in module {type(module).__name__}\")\n",
    "         else:\n",
    "             logger.debug(f\"No pruning mask found on 'weight' in module {type(module).__name__} (already removed or never pruned).\")\n",
    "\n",
    "\n",
    "    logger.info(\"Pruning made permanent.\")\n",
    "\n",
    "    # Verify Sparsity After Removal \n",
    "    final_sparsity, final_zeros, final_total = calculate_global_sparsity(parameters_to_prune_refined)\n",
    "    logger.info(f\"Final sparsity after mask removal: {final_sparsity:.2f}%\")\n",
    "    logger.info(f\"Total LoRA parameters considered for pruning: {final_total}\")\n",
    "    logger.info(f\"Total zeroed parameters in LoRA layers: {final_zeros}\")\n",
    "\n",
    "    # The model `lora_model` now has its LoRA weights permanently pruned.\n",
    "    logger.info(\"Pruning process complete. `lora_model` has been modified in-place.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "095231da-a453-461e-b8f8-9df8fd22741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 21:49:45,507 - INFO - Sample pruned weight tensor (first 5x5 elements or less):\n",
      " tensor([[-0.0074, -0.0371,  0.0000, -0.0119,  0.0086],\n",
      "        [-0.0261,  0.0308,  0.0267, -0.0399, -0.0366],\n",
      "        [ 0.0276,  0.0404,  0.0295, -0.0247,  0.0282],\n",
      "        [ 0.0227,  0.0194, -0.0290, -0.0091,  0.0161],\n",
      "        [-0.0155,  0.0124, -0.0163,  0.0222, -0.0000]], device='cuda:0')\n",
      "2025-05-03 21:49:45,509 - INFO - Sparsity of this sample tensor: 16.02%\n"
     ]
    }
   ],
   "source": [
    "# Checking a specific pruned weight matrix \n",
    "try:\n",
    " module_to_inspect = target_modules_refined[0] # Getting the first module we pruned\n",
    " weight_tensor = module_to_inspect.weight \n",
    " logger.info(f\"Sample pruned weight tensor (first 5x5 elements or less):\\n {weight_tensor.data[:5,:5]}\")\n",
    " sparsity_sample = 100. * float(torch.sum(weight_tensor == 0)) / float(weight_tensor.nelement())\n",
    " logger.info(f\"Sparsity of this sample tensor: {sparsity_sample:.2f}%\")\n",
    "except IndexError:\n",
    " logger.info(\"Cannot show sample tensor, no parameters were identified for pruning.\")\n",
    "except AttributeError:\n",
    " logger.info(\"Cannot show sample tensor, module structure might have changed unexpectedly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc74624d-174f-49be-9ebc-129151692040",
   "metadata": {},
   "source": [
    "# Unstructured Pruning Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5626c7c1-5a0e-4f22-a79f-c9d05c3ad879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 02:45:32,917 - INFO - \n",
      "==================================================\n",
      "2025-05-03 02:45:32,919 - INFO - Starting Benchmarks for PRUNED LoRA Model\n",
      "2025-05-03 02:45:32,919 - INFO - Pruned Model Sparsity: 50.00%\n",
      "2025-05-03 02:45:32,920 - INFO - ==================================================\n",
      "\n",
      "2025-05-03 02:45:32,921 - INFO - \n",
      "Running benchmark for PRUNED LoRA model with batch_size=8, max_length=128\n",
      "2025-05-03 02:45:32,921 - INFO - Configuration:\n",
      "2025-05-03 02:45:32,922 - INFO -   • Model:      Pruned LoRA on GPT-2 (50.0% sparse)\n",
      "2025-05-03 02:45:32,923 - INFO -   • Batch size: 8\n",
      "2025-05-03 02:45:32,923 - INFO -   • Max length: 128\n",
      "2025-05-03 02:45:59,269 - INFO - \n",
      "Training (Pruned Model):\n",
      "2025-05-03 02:45:59,271 - INFO -   Average time per batch:    0.0868 ± 0.0209 seconds\n",
      "2025-05-03 02:45:59,271 - INFO -   Average memory usage:      785.15 ± 80.33 MB\n",
      "2025-05-03 02:45:59,272 - INFO -   Average throughput:        106.13 ± 58.68 samples/second\n",
      "2025-05-03 02:45:59,272 - INFO -   Average loss:              2.5132 ± 0.6692\n",
      "2025-05-03 02:45:59,273 - INFO -   Average perplexity:        15.6570 ± 12.9634\n",
      "2025-05-03 02:45:59,273 - INFO - \n",
      "Inference (Pruned Model):\n",
      "2025-05-03 02:45:59,274 - INFO -   Average time per batch:    0.0776 ± 0.0193 seconds\n",
      "2025-05-03 02:45:59,274 - INFO -   Average memory usage:      790.39 ± 73.02 MB\n",
      "2025-05-03 02:45:59,275 - INFO -   Average throughput:        133.22 ± 125.14 samples/second\n",
      "2025-05-03 02:45:59,275 - INFO -   Average perplexity:        14.8198 ± 12.2142\n",
      "2025-05-03 02:45:59,276 - INFO - \n",
      "Running benchmark for PRUNED LoRA model with batch_size=16, max_length=128\n",
      "2025-05-03 02:45:59,276 - INFO - Configuration:\n",
      "2025-05-03 02:45:59,277 - INFO -   • Model:      Pruned LoRA on GPT-2 (50.0% sparse)\n",
      "2025-05-03 02:45:59,277 - INFO -   • Batch size: 16\n",
      "2025-05-03 02:45:59,278 - INFO -   • Max length: 128\n",
      "2025-05-03 02:46:54,295 - INFO - \n",
      "Training (Pruned Model):\n",
      "2025-05-03 02:46:54,296 - INFO -   Average time per batch:    0.1818 ± 0.0281 seconds\n",
      "2025-05-03 02:46:54,297 - INFO -   Average memory usage:      1101.72 ± 97.45 MB\n",
      "2025-05-03 02:46:54,298 - INFO -   Average throughput:        95.42 ± 48.74 samples/second\n",
      "2025-05-03 02:46:54,299 - INFO -   Average loss:              2.4040 ± 0.5940\n",
      "2025-05-03 02:46:54,299 - INFO -   Average perplexity:        13.0113 ± 7.5754\n",
      "2025-05-03 02:46:54,300 - INFO - \n",
      "Inference (Pruned Model):\n",
      "2025-05-03 02:46:54,300 - INFO -   Average time per batch:    0.1552 ± 0.0369 seconds\n",
      "2025-05-03 02:46:54,301 - INFO -   Average memory usage:      1076.14 ± 138.70 MB\n",
      "2025-05-03 02:46:54,301 - INFO -   Average throughput:        129.40 ± 118.50 samples/second\n",
      "2025-05-03 02:46:54,302 - INFO -   Average perplexity:        11.6376 ± 7.9914\n",
      "2025-05-03 02:46:54,302 - INFO - \n",
      "Running benchmark for PRUNED LoRA model with batch_size=32, max_length=128\n",
      "2025-05-03 02:46:54,303 - INFO - Configuration:\n",
      "2025-05-03 02:46:54,303 - INFO -   • Model:      Pruned LoRA on GPT-2 (50.0% sparse)\n",
      "2025-05-03 02:46:54,304 - INFO -   • Batch size: 32\n",
      "2025-05-03 02:46:54,305 - INFO -   • Max length: 128\n",
      "2025-05-03 02:48:46,531 - INFO - \n",
      "Training (Pruned Model):\n",
      "2025-05-03 02:48:46,533 - INFO -   Average time per batch:    0.3515 ± 0.0341 seconds\n",
      "2025-05-03 02:48:46,533 - INFO -   Average memory usage:      1712.77 ± 121.31 MB\n",
      "2025-05-03 02:48:46,534 - INFO -   Average throughput:        94.10 ± 33.83 samples/second\n",
      "2025-05-03 02:48:46,534 - INFO -   Average loss:              2.2043 ± 0.5461\n",
      "2025-05-03 02:48:46,535 - INFO -   Average perplexity:        10.4070 ± 5.3139\n",
      "2025-05-03 02:48:46,535 - INFO - \n",
      "Inference (Pruned Model):\n",
      "2025-05-03 02:48:46,536 - INFO -   Average time per batch:    0.3252 ± 0.0501 seconds\n",
      "2025-05-03 02:48:46,536 - INFO -   Average memory usage:      1692.19 ± 182.86 MB\n",
      "2025-05-03 02:48:46,536 - INFO -   Average throughput:        106.62 ± 54.24 samples/second\n",
      "2025-05-03 02:48:46,538 - INFO -   Average perplexity:        9.5485 ± 4.8155\n",
      "2025-05-03 02:48:46,538 - INFO - \n",
      "==================================================\n",
      "2025-05-03 02:48:46,539 - INFO - Benchmarking for PRUNED LoRA Model Complete\n",
      "2025-05-03 02:48:46,539 - INFO - ==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import logging\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer \n",
    "\n",
    "if not logger.hasHandlers():\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info(\"\\n\" + \"=\"*50)\n",
    "logger.info(\"Starting Benchmarks for PRUNED LoRA Model\")\n",
    "logger.info(f\"Pruned Model Sparsity: {final_sparsity:.2f}%\")\n",
    "logger.info(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# Re-running the exact same benchmark loop on the PRUNED model \n",
    "for bs in [8, 16, 32]:\n",
    "    logger.info(f\"\\nRunning benchmark for PRUNED LoRA model with batch_size={bs}, max_length={max_length}\")\n",
    "    logger.info(\"Configuration:\")\n",
    "    logger.info(f\"  • Model:      Pruned LoRA on GPT-2 ({final_sparsity:.1f}% sparse)\")\n",
    "    logger.info(f\"  • Batch size: {bs}\")\n",
    "    logger.info(f\"  • Max length: {max_length}\")\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "    train_stats, infer_stats = benchmark_loRA(\n",
    "        lora_model, tokenizer, dataset, # Passing the pruned lora_model\n",
    "        batch_size=bs, max_length=max_length,\n",
    "        num_train_batches=100, num_infer_batches=100\n",
    "    )\n",
    "\n",
    "    # Training results for the pruned model\n",
    "    t = train_stats\n",
    "    logger.info(\"\\nTraining (Pruned Model):\")\n",
    "    logger.info(f\"  Average time per batch:    {t['time'][0]:.4f} ± {t['time'][1]:.4f} seconds\")\n",
    "    logger.info(f\"  Average memory usage:      {t['memory'][0]:.2f} ± {t['memory'][1]:.2f} MB\")\n",
    "    logger.info(f\"  Average throughput:        {t['throughput'][0]:.2f} ± {t['throughput'][1]:.2f} samples/second\")\n",
    "    logger.info(f\"  Average loss:              {t['loss'][0]:.4f} ± {t['loss'][1]:.4f}\")\n",
    "    logger.info(f\"  Average perplexity:        {t['perplexity'][0]:.4f} ± {t['perplexity'][1]:.4f}\")\n",
    "\n",
    "    # Inference results for the pruned model\n",
    "    i = infer_stats\n",
    "    logger.info(\"\\nInference (Pruned Model):\")\n",
    "    logger.info(f\"  Average time per batch:    {i['time'][0]:.4f} ± {i['time'][1]:.4f} seconds\")\n",
    "    logger.info(f\"  Average memory usage:      {i['memory'][0]:.2f} ± {i['memory'][1]:.2f} MB\")\n",
    "    logger.info(f\"  Average throughput:        {i['throughput'][0]:.2f} ± {i['throughput'][1]:.2f} samples/second\")\n",
    "    logger.info(f\"  Average perplexity:        {i['perplexity'][0]:.4f} ± {i['perplexity'][1]:.4f}\")\n",
    "\n",
    "logger.info(\"\\n\" + \"=\"*50)\n",
    "logger.info(\"Benchmarking for PRUNED LoRA Model Complete\")\n",
    "logger.info(\"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ade1b-70d6-44d5-b2ea-e1734bf52838",
   "metadata": {},
   "source": [
    "# Final Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb9f0ae-9960-4831-8391-38a8fc23ee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:08:20,890 - INFO - Using device: cuda\n",
      "2025-05-03 22:08:20,890 - INFO - Using device: cuda\n",
      "2025-05-03 22:08:20,892 - INFO - Loading wikitext-2 dataset...\n",
      "2025-05-03 22:08:20,892 - INFO - Loading wikitext-2 dataset...\n",
      "2025-05-03 22:08:24,893 - INFO - Loading tokenizer...\n",
      "2025-05-03 22:08:24,893 - INFO - Loading tokenizer...\n",
      "2025-05-03 22:08:25,402 - INFO - Dataset and tokenizer loaded.\n",
      "2025-05-03 22:08:25,402 - INFO - Dataset and tokenizer loaded.\n",
      "2025-05-03 22:08:25,404 - INFO - \n",
      "===== Starting Baseline Full Fine-tune Benchmark =====\n",
      "2025-05-03 22:08:25,404 - INFO - \n",
      "===== Starting Baseline Full Fine-tune Benchmark =====\n",
      "2025-05-03 22:08:26,060 - INFO - --- Starting Baseline ---\n",
      "2025-05-03 22:08:26,060 - INFO - --- Starting Baseline ---\n",
      "2025-05-03 22:08:26,061 - INFO - Target PPL: 15, LR: 5e-05, Batch Size: 16, Eval Every: 500\n",
      "2025-05-03 22:08:26,061 - INFO - Target PPL: 15, LR: 5e-05, Batch Size: 16, Eval Every: 500\n",
      "2025-05-03 22:08:26,062 - INFO - Train samples: 23767, Val samples: 2461\n",
      "2025-05-03 22:08:26,062 - INFO - Train samples: 23767, Val samples: 2461\n",
      "2025-05-03 22:13:13,214 - INFO - [Baseline Step 500/29700] val_ppl=8.07 (Best: inf) loss=2.181 lr=5.0e-05 time=0.08h peak_mem=2554.6MB\n",
      "2025-05-03 22:13:13,214 - INFO - [Baseline Step 500/29700] val_ppl=8.07 (Best: inf) loss=2.181 lr=5.0e-05 time=0.08h peak_mem=2554.6MB\n",
      "2025-05-03 22:13:13,215 - INFO - --- Target PPL 15 reached for Baseline ---\n",
      "2025-05-03 22:13:13,215 - INFO - --- Target PPL 15 reached for Baseline ---\n",
      "2025-05-03 22:13:13,219 - INFO - Baseline results: {'steps': 500, 'total_hours': 0.07976534042093489, 'peak_mem_mb': 2554.64306640625, 'final_ppl': 8.070260214305394}\n",
      "2025-05-03 22:13:13,219 - INFO - Baseline results: {'steps': 500, 'total_hours': 0.07976534042093489, 'peak_mem_mb': 2554.64306640625, 'final_ppl': 8.070260214305394}\n",
      "2025-05-03 22:13:13,539 - INFO - \n",
      "===== Starting LoRA Fine-tune Benchmark =====\n",
      "2025-05-03 22:13:13,539 - INFO - \n",
      "===== Starting LoRA Fine-tune Benchmark =====\n",
      "/home/tgs2126/py39_env/lib/python3.9/site-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "2025-05-03 22:13:14,178 - INFO - Injected LoRA adapters for LoRA run.\n",
      "2025-05-03 22:13:14,178 - INFO - Injected LoRA adapters for LoRA run.\n",
      "2025-05-03 22:13:14,181 - INFO - --- Starting LoRA ---\n",
      "2025-05-03 22:13:14,181 - INFO - --- Starting LoRA ---\n",
      "2025-05-03 22:13:14,182 - INFO - Target PPL: 15, LR: 0.0001, Batch Size: 16, Eval Every: 500\n",
      "2025-05-03 22:13:14,182 - INFO - Target PPL: 15, LR: 0.0001, Batch Size: 16, Eval Every: 500\n",
      "2025-05-03 22:13:14,183 - INFO - Train samples: 23767, Val samples: 2461\n",
      "2025-05-03 22:13:14,183 - INFO - Train samples: 23767, Val samples: 2461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.2364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:16:41,771 - INFO - [LoRA Step 500/29700] val_ppl=8.86 (Best: inf) loss=2.242 lr=1.0e-04 time=0.06h peak_mem=1606.7MB\n",
      "2025-05-03 22:16:41,771 - INFO - [LoRA Step 500/29700] val_ppl=8.86 (Best: inf) loss=2.242 lr=1.0e-04 time=0.06h peak_mem=1606.7MB\n",
      "2025-05-03 22:16:41,773 - INFO - --- Target PPL 15 reached for LoRA ---\n",
      "2025-05-03 22:16:41,773 - INFO - --- Target PPL 15 reached for LoRA ---\n",
      "2025-05-03 22:16:41,775 - INFO - LoRA results: {'steps': 500, 'total_hours': 0.05766450901826223, 'peak_mem_mb': 1606.72998046875, 'final_ppl': 8.85861130128496}\n",
      "2025-05-03 22:16:41,775 - INFO - LoRA results: {'steps': 500, 'total_hours': 0.05766450901826223, 'peak_mem_mb': 1606.72998046875, 'final_ppl': 8.85861130128496}\n",
      "2025-05-03 22:16:42,054 - INFO - \n",
      "===== Starting Pruned LoRA Fine-tune Benchmark =====\n",
      "2025-05-03 22:16:42,054 - INFO - \n",
      "===== Starting Pruned LoRA Fine-tune Benchmark =====\n",
      "2025-05-03 22:16:42,697 - INFO - Injected LoRA adapters for Pruned LoRA run.\n",
      "2025-05-03 22:16:42,697 - INFO - Injected LoRA adapters for Pruned LoRA run.\n",
      "2025-05-03 22:16:42,699 - INFO - Applying 80.0% global unstructured pruning to LoRA weights...\n",
      "2025-05-03 22:16:42,699 - INFO - Applying 80.0% global unstructured pruning to LoRA weights...\n",
      "2025-05-03 22:16:42,702 - INFO - Identified 24 parameter tensors for pruning.\n",
      "2025-05-03 22:16:42,702 - INFO - Identified 24 parameter tensors for pruning.\n",
      "2025-05-03 22:16:42,706 - INFO - Pruning mask applied. Making pruning permanent...\n",
      "2025-05-03 22:16:42,706 - INFO - Pruning mask applied. Making pruning permanent...\n",
      "2025-05-03 22:16:42,710 - INFO - Pruning made permanent. Achieved sparsity: 80.00%\n",
      "2025-05-03 22:16:42,710 - INFO - Pruning made permanent. Achieved sparsity: 80.00%\n",
      "2025-05-03 22:16:42,712 - INFO - --- Starting Pruned LoRA ---\n",
      "2025-05-03 22:16:42,712 - INFO - --- Starting Pruned LoRA ---\n",
      "2025-05-03 22:16:42,713 - INFO - Target PPL: 15, LR: 0.0001, Batch Size: 16, Eval Every: 500\n",
      "2025-05-03 22:16:42,713 - INFO - Target PPL: 15, LR: 0.0001, Batch Size: 16, Eval Every: 500\n",
      "2025-05-03 22:16:42,714 - INFO - Train samples: 23767, Val samples: 2461\n",
      "2025-05-03 22:16:42,714 - INFO - Train samples: 23767, Val samples: 2461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.2364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:20:10,194 - INFO - [Pruned LoRA Step 500/29700] val_ppl=8.89 (Best: inf) loss=2.260 lr=1.0e-04 time=0.06h peak_mem=1605.7MB\n",
      "2025-05-03 22:20:10,194 - INFO - [Pruned LoRA Step 500/29700] val_ppl=8.89 (Best: inf) loss=2.260 lr=1.0e-04 time=0.06h peak_mem=1605.7MB\n",
      "2025-05-03 22:20:10,195 - INFO - --- Target PPL 15 reached for Pruned LoRA ---\n",
      "2025-05-03 22:20:10,195 - INFO - --- Target PPL 15 reached for Pruned LoRA ---\n",
      "2025-05-03 22:20:10,197 - INFO - Pruned LoRA results: {'steps': 500, 'total_hours': 0.05763408190674252, 'peak_mem_mb': 1605.74560546875, 'final_ppl': 8.8861300780317}\n",
      "2025-05-03 22:20:10,197 - INFO - Pruned LoRA results: {'steps': 500, 'total_hours': 0.05763408190674252, 'peak_mem_mb': 1605.74560546875, 'final_ppl': 8.8861300780317}\n",
      "2025-05-03 22:20:10,472 - INFO - \n",
      "===== Benchmark Comparison =====\n",
      "2025-05-03 22:20:10,472 - INFO - \n",
      "===== Benchmark Comparison =====\n",
      "2025-05-03 22:20:10,478 - INFO - \n",
      "Comparison DataFrame:\n",
      "                  Steps Total Hours (h) Peak GPU Mem (MB) Final Val Perplexity\n",
      "Baseline            500            0.08           2,554.6                 8.07\n",
      "LoRA                500            0.06           1,606.7                 8.86\n",
      "Pruned LoRA (80%)   500            0.06           1,605.7                 8.89\n",
      "2025-05-03 22:20:10,478 - INFO - \n",
      "Comparison DataFrame:\n",
      "                  Steps Total Hours (h) Peak GPU Mem (MB) Final Val Perplexity\n",
      "Baseline            500            0.08           2,554.6                 8.07\n",
      "LoRA                500            0.06           1,606.7                 8.86\n",
      "Pruned LoRA (80%)   500            0.06           1,605.7                 8.89\n",
      "2025-05-03 22:20:10,479 - INFO - \n",
      "===== Script Finished =====\n",
      "2025-05-03 22:20:10,479 - INFO - \n",
      "===== Script Finished =====\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time, math, logging\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model \n",
    "from peft.tuners.lora import LoraLayer\n",
    "import torch.nn.utils.prune as prune\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# setup\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "model_name = \"gpt2\"\n",
    "max_length = 128\n",
    "target_ppl = 15\n",
    "eval_every = 500\n",
    "batch_size = 16\n",
    "pruning_amount = 0.8 # 80% sparsity\n",
    "\n",
    "# Dataset and Tokenizer\n",
    "logger.info(\"Loading wikitext-2 dataset...\")\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "logger.info(\"Loading tokenizer...\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_texts_full = [t for t in dataset[\"train\"][\"text\"] if t.strip()]\n",
    "val_texts_full = [t for t in dataset[\"validation\"][\"text\"] if t.strip()]\n",
    "logger.info(\"Dataset and tokenizer loaded.\")\n",
    "\n",
    "\n",
    "# Helper functions \n",
    "def compute_perplexity(model, tokenizer, texts, device,\n",
    "                       batch_size=8, max_length=128):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    total_evaluated = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            if not batch: continue\n",
    "            total_evaluated += len(batch)\n",
    "            inputs = tokenizer(batch, padding=True, truncation=True,\n",
    "                               max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "            outputs = model(**inputs, labels=inputs.input_ids)\n",
    "            if hasattr(outputs, 'loss') and outputs.loss is not None:\n",
    "                 losses.append(outputs.loss.item() * len(batch)) \n",
    "                 pass \n",
    "\n",
    "    if not losses or total_evaluated == 0:\n",
    "         return float('inf')\n",
    "\n",
    "    avg_loss = sum(losses) / total_evaluated\n",
    "    if avg_loss <= 0:\n",
    "         return float('inf')\n",
    "    return math.exp(avg_loss)\n",
    "\n",
    "def train_until(model, tokenizer, train_texts, val_texts, target_ppl,\n",
    "                device, lr=5e-5, batch_size=8, max_length=128,\n",
    "                eval_every=500, run_label=\"Training\"):\n",
    "    optimizer   = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    start_time = time.time()\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "    step = 0\n",
    "    max_steps = (len(train_texts) // batch_size) * 20\n",
    "    logger.info(f\"--- Starting {run_label} ---\")\n",
    "    logger.info(f\"Target PPL: {target_ppl}, LR: {lr}, Batch Size: {batch_size}, Eval Every: {eval_every}\")\n",
    "    logger.info(f\"Train samples: {len(train_texts)}, Val samples: {len(val_texts)}\")\n",
    "    model.train()\n",
    "\n",
    "    best_ppl = float('inf')\n",
    "\n",
    "    while True:\n",
    "        model.train()\n",
    "        for i in range(0, len(train_texts), batch_size):\n",
    "            batch  = train_texts[i:i+batch_size]\n",
    "            if not batch: continue\n",
    "\n",
    "            inputs = tokenizer(batch, padding=True, truncation=True,\n",
    "                               max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "\n",
    "            outputs = model(**inputs, labels=inputs.input_ids)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            if loss is None:\n",
    "                step += 1\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), 1.0)\n",
    "            optimizer.step()\n",
    "            model.zero_grad(set_to_none=True)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            if step % eval_every == 0:\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                val_ppl = compute_perplexity(model, tokenizer, val_texts, device,\n",
    "                                             batch_size=batch_size, max_length=max_length)\n",
    "                elapsed_h = (time.time() - start_time) / 3600\n",
    "                if device == torch.device(\"cuda\"):\n",
    "                    peak_mem = torch.cuda.memory_allocated(device) / 1024**2\n",
    "                else:\n",
    "                    peak_mem = 0\n",
    "\n",
    "                logger.info(f\"[{run_label} Step {step}/{max_steps}] val_ppl={val_ppl:.2f} (Best: {best_ppl:.2f}) loss={loss.item():.3f} lr={current_lr:.1e} time={elapsed_h:.2f}h peak_mem={peak_mem:.1f}MB\")\n",
    "\n",
    "                if val_ppl <= target_ppl:\n",
    "                    total_h = (time.time() - start_time) / 3600\n",
    "                    final_mem = peak_mem\n",
    "                    logger.info(f\"--- Target PPL {target_ppl} reached for {run_label} ---\")\n",
    "                    return {\n",
    "                        \"steps\":       step,\n",
    "                        \"total_hours\": total_h,\n",
    "                        \"peak_mem_mb\": final_mem,\n",
    "                        \"final_ppl\":   val_ppl\n",
    "                    }\n",
    "\n",
    "                best_ppl = min(best_ppl, val_ppl)\n",
    "                model.train()\n",
    "\n",
    "            if step >= max_steps:\n",
    "                 logger.warning(f\"{run_label} did not reach target PPL within {max_steps} steps. Returning current state.\")\n",
    "                 total_h = (time.time() - start_time) / 3600\n",
    "                 final_mem = torch.cuda.memory_allocated(device) / 1024**2 if device == torch.device(\"cuda\") else 0\n",
    "                 return {\n",
    "                     \"steps\": step,\n",
    "                     \"total_hours\": total_h,\n",
    "                     \"peak_mem_mb\": final_mem,\n",
    "                     \"final_ppl\": best_ppl \n",
    "                 }\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "#  Baseline full fine-tune benchmark \n",
    "logger.info(\"\\n===== Starting Baseline Full Fine-tune Benchmark =====\")\n",
    "baseline_model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "for p in baseline_model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "baseline_res = train_until(\n",
    "    baseline_model, tokenizer, train_texts_full, val_texts_full, target_ppl=target_ppl,\n",
    "    device=device, lr=5e-5, batch_size=batch_size, max_length=max_length,\n",
    "    eval_every=eval_every, run_label=\"Baseline\"\n",
    ")\n",
    "logger.info(f\"Baseline results: {baseline_res}\")\n",
    "\n",
    "# after baseline finishes\n",
    "del baseline_model\n",
    "gc.collect()\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "#  LoRA fine-tune benchmark \n",
    "logger.info(\"\\n===== Starting LoRA Fine-tune Benchmark =====\")\n",
    "base_model_lora = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "for param in base_model_lora.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"c_attn\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "lora_model = get_peft_model(base_model_lora, lora_cfg)\n",
    "logger.info(\"Injected LoRA adapters for LoRA run.\")\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "lora_res = train_until(\n",
    "    lora_model, tokenizer, train_texts_full, val_texts_full, target_ppl=target_ppl,\n",
    "    device=device, lr=1e-4, batch_size=batch_size, max_length=max_length,\n",
    "    eval_every=eval_every, run_label=\"LoRA\"\n",
    ")\n",
    "logger.info(f\"LoRA results: {lora_res}\")\n",
    "\n",
    "# after LoRA finishes\n",
    "del base_model_lora, lora_model\n",
    "gc.collect()\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "#  Pruned LoRA Fine-tune Benchmark \n",
    "logger.info(\"\\n===== Starting Pruned LoRA Fine-tune Benchmark =====\")\n",
    "# Load base model again\n",
    "base_model_pruned = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "for param in base_model_pruned.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Apply LoRA config again\n",
    "lora_model_pruned = get_peft_model(base_model_pruned, lora_cfg)\n",
    "logger.info(\"Injected LoRA adapters for Pruned LoRA run.\")\n",
    "lora_model_pruned.print_trainable_parameters()\n",
    "\n",
    "# --- Apply Pruning BEFORE Training ---\n",
    "logger.info(f\"Applying {pruning_amount:.1%} global unstructured pruning to LoRA weights...\")\n",
    "parameters_to_prune = []\n",
    "target_modules = set()\n",
    "for name, module in lora_model_pruned.named_modules():\n",
    "     if isinstance(module, LoraLayer):\n",
    "         for key in ['lora_A', 'lora_B']:\n",
    "            if hasattr(module, key):\n",
    "                sub_module_dict = getattr(module, key)\n",
    "                if isinstance(sub_module_dict, torch.nn.ModuleDict):\n",
    "                     for adapter_name, sub_module in sub_module_dict.items():\n",
    "                         if hasattr(sub_module, 'weight'):\n",
    "                            parameters_to_prune.append((sub_module, 'weight'))\n",
    "                            target_modules.add(sub_module)\n",
    "                elif isinstance(sub_module_dict, torch.nn.Module):\n",
    "                    if hasattr(sub_module_dict, 'weight'):\n",
    "                        parameters_to_prune.append((sub_module_dict, 'weight'))\n",
    "                        target_modules.add(sub_module_dict)\n",
    "\n",
    "if not parameters_to_prune:\n",
    "    logger.warning(\"Could not find any LoRA parameters to prune!\")\n",
    "    pruned_lora_res = {\"steps\": -1, \"total_hours\": -1, \"peak_mem_mb\": -1, \"final_ppl\": -1}\n",
    "else:\n",
    "    logger.info(f\"Identified {len(parameters_to_prune)} parameter tensors for pruning.\")\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=pruning_amount,\n",
    "    )\n",
    "    logger.info(\"Pruning mask applied. Making pruning permanent...\")\n",
    "    final_total_params = 0\n",
    "    final_zero_params = 0\n",
    "    for module in target_modules:\n",
    "        if prune.is_pruned(module):\n",
    "             param = getattr(module, 'weight')\n",
    "             final_total_params += param.nelement()\n",
    "             final_zero_params += torch.sum(param == 0).item()\n",
    "             prune.remove(module, 'weight')\n",
    "        else:\n",
    "             param = getattr(module, 'weight')\n",
    "             final_total_params += param.nelement()\n",
    "\n",
    "\n",
    "    if final_total_params > 0:\n",
    "        final_sparsity = 100. * float(final_zero_params) / float(final_total_params)\n",
    "        logger.info(f\"Pruning made permanent. Achieved sparsity: {final_sparsity:.2f}%\")\n",
    "    else:\n",
    "        logger.info(\"Pruning made permanent (no parameters found).\")\n",
    "\n",
    "\n",
    "    #  Train the Pruned LoRA Model \n",
    "    pruned_lora_res = train_until(\n",
    "        lora_model_pruned, tokenizer, train_texts_full, val_texts_full, target_ppl=target_ppl,\n",
    "        device=device, lr=1e-4, batch_size=batch_size, max_length=max_length,\n",
    "        eval_every=eval_every, run_label=\"Pruned LoRA\"\n",
    "    )\n",
    "    logger.info(f\"Pruned LoRA results: {pruned_lora_res}\")\n",
    "\n",
    "# after Pruned LoRA finishes\n",
    "del base_model_pruned, lora_model_pruned\n",
    "gc.collect()\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "#  Comparison \n",
    "logger.info(\"\\n===== Benchmark Comparison =====\")\n",
    "\n",
    "results_list = []\n",
    "indices = []\n",
    "if 'steps' in baseline_res and baseline_res['steps'] != -1:\n",
    "    results_list.append(baseline_res)\n",
    "    indices.append(\"Baseline\")\n",
    "\n",
    "if 'steps' in lora_res and lora_res['steps'] != -1:\n",
    "    results_list.append(lora_res)\n",
    "    indices.append(\"LoRA\")\n",
    "\n",
    "# Ensure pruned_lora_res exists even if pruning failed\n",
    "if 'pruned_lora_res' not in locals():\n",
    "     pruned_lora_res = {\"steps\": -1, \"total_hours\": -1, \"peak_mem_mb\": -1, \"final_ppl\": -1}\n",
    "\n",
    "\n",
    "if 'steps' in pruned_lora_res and pruned_lora_res['steps'] != -1:\n",
    "    results_list.append(pruned_lora_res)\n",
    "    indices.append(f\"Pruned LoRA ({pruning_amount:.0%})\")\n",
    "\n",
    "\n",
    "if results_list:\n",
    "    df = pd.DataFrame(results_list, index=indices)\n",
    "    df.rename(columns={\n",
    "        \"steps\": \"Steps\",\n",
    "        \"total_hours\": \"Total Hours (h)\",\n",
    "        \"peak_mem_mb\": \"Peak GPU Mem (MB)\",\n",
    "        \"final_ppl\": \"Final Val Perplexity\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Format the DataFrame\n",
    "    df['Steps'] = df['Steps'].map('{:,.0f}'.format)\n",
    "    df['Total Hours (h)'] = df['Total Hours (h)'].map('{:.2f}'.format)\n",
    "    df['Peak GPU Mem (MB)'] = df['Peak GPU Mem (MB)'].map('{:,.1f}'.format)\n",
    "    df['Final Val Perplexity'] = df['Final Val Perplexity'].map('{:.2f}'.format)\n",
    "\n",
    "    logger.info(\"\\nComparison DataFrame:\\n%s\", df.to_string())\n",
    "else:\n",
    "    logger.error(\"No successful benchmark runs to compare.\")\n",
    "\n",
    "logger.info(\"\\n===== Script Finished =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f20bb13d-555f-4217-be0b-1555d640bece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/tgs2126/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtaners\u001b[0m (\u001b[33mhpml_final_project\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d01811a2-64de-4571-bbeb-90e4e5871ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tgs2126/wandb/run-20250503_225657-c9x32x94</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison/runs/c9x32x94' target=\"_blank\">Manual Log - Run ending PPL ~8-9 (80% Pruning)</a></strong> to <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison' target=\"_blank\">https://wandb.ai/hpml_final_project/lora-pruning-comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison/runs/c9x32x94' target=\"_blank\">https://wandb.ai/hpml_final_project/lora-pruning-comparison/runs/c9x32x94</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb initialized.\n",
      "Summary metrics logged.\n",
      "\n",
      "Dat;aFrame Logged to Wandb:\n",
      "                  Steps Total Hours (h) Peak GPU Mem (MB) Final Val Perplexity\n",
      "Baseline            500            0.08           2,554.6                 8.07\n",
      "LoRA                500            0.06           1,606.7                 8.86\n",
      "Pruned LoRA (80%)   500            0.06           1,605.7                 8.89\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Summary/Baseline/final_ppl</td><td>▁</td></tr><tr><td>Summary/Baseline/peak_mem_mb</td><td>▁</td></tr><tr><td>Summary/Baseline/steps</td><td>▁</td></tr><tr><td>Summary/Baseline/total_hours</td><td>▁</td></tr><tr><td>Summary/LoRA/final_ppl</td><td>▁</td></tr><tr><td>Summary/LoRA/peak_mem_mb</td><td>▁</td></tr><tr><td>Summary/LoRA/steps</td><td>▁</td></tr><tr><td>Summary/LoRA/total_hours</td><td>▁</td></tr><tr><td>Summary/Pruned LoRA (80%)/final_ppl</td><td>▁</td></tr><tr><td>Summary/Pruned LoRA (80%)/peak_mem_mb</td><td>▁</td></tr><tr><td>Summary/Pruned LoRA (80%)/steps</td><td>▁</td></tr><tr><td>Summary/Pruned LoRA (80%)/total_hours</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Summary/Baseline/final_ppl</td><td>8.07</td></tr><tr><td>Summary/Baseline/peak_mem_mb</td><td>2554.6</td></tr><tr><td>Summary/Baseline/steps</td><td>500</td></tr><tr><td>Summary/Baseline/total_hours</td><td>0.08</td></tr><tr><td>Summary/LoRA/final_ppl</td><td>8.86</td></tr><tr><td>Summary/LoRA/peak_mem_mb</td><td>1606.7</td></tr><tr><td>Summary/LoRA/steps</td><td>500</td></tr><tr><td>Summary/LoRA/total_hours</td><td>0.06</td></tr><tr><td>Summary/Pruned LoRA (80%)/final_ppl</td><td>8.89</td></tr><tr><td>Summary/Pruned LoRA (80%)/peak_mem_mb</td><td>1605.7</td></tr><tr><td>Summary/Pruned LoRA (80%)/steps</td><td>500</td></tr><tr><td>Summary/Pruned LoRA (80%)/total_hours</td><td>0.06</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Manual Log - Run ending PPL ~8-9 (80% Pruning)</strong> at: <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison/runs/c9x32x94' target=\"_blank\">https://wandb.ai/hpml_final_project/lora-pruning-comparison/runs/c9x32x94</a><br> View project at: <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison' target=\"_blank\">https://wandb.ai/hpml_final_project/lora-pruning-comparison</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250503_225657-c9x32x94/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb run finished.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import math\n",
    "import logging\n",
    "\n",
    "#  Configuration \n",
    "config_manual = {\n",
    "    \"model_name\": \"gpt2\",\n",
    "    \"max_length\": 128,\n",
    "    \"num_train_epochs_intended\": 1,\n",
    "    \"batch_size\": 16,\n",
    "    \"pruning_amount\": 0.8,\n",
    "    \"lora_r\": 8,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_target_modules\": [\"c_attn\"],\n",
    "    \"baseline_lr\": 5e-5,\n",
    "    \"lora_lr\": 1e-4,\n",
    "    \"eval_every_steps\": 500,\n",
    "    \"target_ppl_set\": 15,\n",
    "    \"device\": \"cuda\",\n",
    "    \"memory_metric\": \"torch.cuda.memory_allocated\"\n",
    "}\n",
    "\n",
    "#  Results \n",
    "baseline_res_manual = {\n",
    "    \"steps\": 500, \"total_hours\": 0.08, \"peak_mem_mb\": 2554.6, \"final_ppl\": 8.07\n",
    "}\n",
    "lora_res_manual = {\n",
    "    \"steps\": 500, \"total_hours\": 0.06, \"peak_mem_mb\": 1606.7, \"final_ppl\": 8.86\n",
    "}\n",
    "pruned_lora_res_manual = {\n",
    "    \"steps\": 500, \"total_hours\": 0.06, \"peak_mem_mb\": 1605.7, \"final_ppl\": 8.89\n",
    "}\n",
    "\n",
    "# Wandb \n",
    "logging.basicConfig(level=logging.INFO) \n",
    "run = None\n",
    "try:\n",
    "    run = wandb.init(\n",
    "        project=\"lora-pruning-comparison\",\n",
    "        config=config_manual,\n",
    "        name=\"Manual Log - Run ending PPL ~8-9 (80% Pruning)\",\n",
    "        job_type=\"logging\"\n",
    "    )\n",
    "    print(\"Wandb initialized.\")\n",
    "    pruning_label = f\"({config_manual['pruning_amount']:.0%})\"\n",
    "    if 'final_ppl' in baseline_res_manual and not math.isnan(baseline_res_manual['final_ppl']):\n",
    "        wandb.log({f\"Summary/Baseline/{k}\": v for k, v in baseline_res_manual.items()})\n",
    "    if 'final_ppl' in lora_res_manual and not math.isnan(lora_res_manual['final_ppl']):\n",
    "         wandb.log({f\"Summary/LoRA/{k}\": v for k, v in lora_res_manual.items()})\n",
    "    if 'final_ppl' in pruned_lora_res_manual and not math.isnan(pruned_lora_res_manual['final_ppl']):\n",
    "         wandb.log({f\"Summary/Pruned LoRA {pruning_label}/{k}\": v for k, v in pruned_lora_res_manual.items()})\n",
    "    print(\"Summary metrics logged.\")\n",
    "\n",
    "    # Log DataFrame\n",
    "    results_list = [baseline_res_manual, lora_res_manual, pruned_lora_res_manual]\n",
    "    indices = [\"Baseline\", \"LoRA\", f\"Pruned LoRA {pruning_label}\"]\n",
    "    valid_results = []\n",
    "    valid_indices = []\n",
    "    for res, idx in zip(results_list, indices):\n",
    "         if res and 'final_ppl' in res and isinstance(res['final_ppl'], (int, float)) and not math.isnan(res['final_ppl']) and not math.isinf(res['final_ppl']):\n",
    "              valid_results.append(res)\n",
    "              valid_indices.append(idx)\n",
    "    if valid_results:\n",
    "        df = pd.DataFrame(valid_results, index=valid_indices)\n",
    "        df.rename(columns={\"steps\": \"Steps\", \"total_hours\": \"Total Hours (h)\", \"peak_mem_mb\": \"Peak GPU Mem (MB)\", \"final_ppl\": \"Final Val Perplexity\"}, inplace=True)\n",
    "        if 'Steps' in df.columns: df['Steps'] = df['Steps'].map('{:,.0f}'.format)\n",
    "        if 'Total Hours (h)' in df.columns: df['Total Hours (h)'] = df['Total Hours (h)'].map('{:.2f}'.format)\n",
    "        if 'Peak GPU Mem (MB)' in df.columns: df['Peak GPU Mem (MB)'] = df['Peak GPU Mem (MB)'].map('{:,.1f}'.format)\n",
    "        if 'Final Val Perplexity' in df.columns: df['Final Val Perplexity'] = df['Final Val Perplexity'].map('{:.2f}'.format)\n",
    "        df_log = df.reset_index().rename(columns={'index': 'Method'})\n",
    "        wandb.log({\"Comparison Table\": wandb.Table(dataframe=df_log)})\n",
    "        print(\"\\nDat;aFrame Logged to Wandb:\")\n",
    "        print(df.to_string())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during wandb processing: {e}\")\n",
    "finally:\n",
    "    if run:\n",
    "        wandb.finish()\n",
    "        print(\"Wandb run finished.\")\n",
    "    else:\n",
    "        print(\"Wandb was not initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31dc79-1345-4a79-883b-bb82384d68f0",
   "metadata": {},
   "source": [
    "# Final Comparison (Baseline vs (Baseline + LORA) vs (Baseline + LORA + Pruning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "360db4d0-35be-4423-bd86-f3b2701cd40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 23:27:12,355 - INFO - Using device: cuda\n",
      "2025-05-03 23:27:12,355 - INFO - Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Baseline_vs_LoRA_vs_Pruned_2Ep_80%</strong> at: <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison-final/runs/f43f0l6z' target=\"_blank\">https://wandb.ai/hpml_final_project/lora-pruning-comparison-final/runs/f43f0l6z</a><br> View project at: <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison-final' target=\"_blank\">https://wandb.ai/hpml_final_project/lora-pruning-comparison-final</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250503_232645-f43f0l6z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tgs2126/wandb/run-20250503_232712-5ws5df62</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison-final/runs/5ws5df62' target=\"_blank\">Baseline_vs_LoRA_vs_Pruned_2Ep_80%</a></strong> to <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison-final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison-final' target=\"_blank\">https://wandb.ai/hpml_final_project/lora-pruning-comparison-final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison-final/runs/5ws5df62' target=\"_blank\">https://wandb.ai/hpml_final_project/lora-pruning-comparison-final/runs/5ws5df62</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 23:27:14,561 - INFO - Weights & Biases initialized successfully.\n",
      "2025-05-03 23:27:14,561 - INFO - Weights & Biases initialized successfully.\n",
      "2025-05-03 23:27:14,564 - INFO - Loading data...\n",
      "2025-05-03 23:27:14,564 - INFO - Loading data...\n",
      "2025-05-03 23:27:18,050 - INFO - Data loaded. Train: 23767, Val/Test: 2461\n",
      "2025-05-03 23:27:18,050 - INFO - Data loaded. Train: 23767, Val/Test: 2461\n",
      "2025-05-03 23:27:18,054 - INFO - \n",
      "===== Starting Baseline Full Fine-tune Training =====\n",
      "2025-05-03 23:27:18,054 - INFO - \n",
      "===== Starting Baseline Full Fine-tune Training =====\n",
      "2025-05-03 23:27:18,675 - INFO - Trainable params (Baseline): 124,439,808\n",
      "2025-05-03 23:27:18,675 - INFO - Trainable params (Baseline): 124,439,808\n",
      "2025-05-03 23:27:18,678 - INFO - --- Starting Baseline ---\n",
      "2025-05-03 23:27:18,678 - INFO - --- Starting Baseline ---\n",
      "2025-05-03 23:27:18,680 - INFO - Epochs: 2, LR: 5e-05, Batch Size: 16, Eval Every: 200\n",
      "2025-05-03 23:27:18,680 - INFO - Epochs: 2, LR: 5e-05, Batch Size: 16, Eval Every: 200\n",
      "2025-05-03 23:27:18,683 - INFO - [Baseline Epoch 1/2] Starting...\n",
      "2025-05-03 23:27:18,683 - INFO - [Baseline Epoch 1/2] Starting...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e9dd5f9aa74a18aab725200ddc562c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/1486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 23:29:34,160 - INFO - [Baseline Step 200/2970] val_ppl=8.43 loss=1.483 time=0.04h peak_mem=8952.9MB\n",
      "2025-05-03 23:29:34,160 - INFO - [Baseline Step 200/2970] val_ppl=8.43 loss=1.483 time=0.04h peak_mem=8952.9MB\n",
      "2025-05-03 23:31:46,731 - INFO - [Baseline Step 400/2970] val_ppl=7.96 loss=1.065 time=0.07h peak_mem=8952.9MB\n",
      "2025-05-03 23:31:46,731 - INFO - [Baseline Step 400/2970] val_ppl=7.96 loss=1.065 time=0.07h peak_mem=8952.9MB\n",
      "2025-05-03 23:34:02,049 - INFO - [Baseline Step 600/2970] val_ppl=8.02 loss=1.709 time=0.11h peak_mem=8952.9MB\n",
      "2025-05-03 23:34:02,049 - INFO - [Baseline Step 600/2970] val_ppl=8.02 loss=1.709 time=0.11h peak_mem=8952.9MB\n",
      "2025-05-03 23:36:16,927 - INFO - [Baseline Step 800/2970] val_ppl=7.87 loss=2.564 time=0.15h peak_mem=8952.9MB\n",
      "2025-05-03 23:36:16,927 - INFO - [Baseline Step 800/2970] val_ppl=7.87 loss=2.564 time=0.15h peak_mem=8952.9MB\n",
      "2025-05-03 23:38:30,734 - INFO - [Baseline Step 1000/2970] val_ppl=7.66 loss=2.637 time=0.19h peak_mem=8952.9MB\n",
      "2025-05-03 23:38:30,734 - INFO - [Baseline Step 1000/2970] val_ppl=7.66 loss=2.637 time=0.19h peak_mem=8952.9MB\n",
      "2025-05-03 23:40:45,698 - INFO - [Baseline Step 1200/2970] val_ppl=7.66 loss=2.064 time=0.22h peak_mem=8954.7MB\n",
      "2025-05-03 23:40:45,698 - INFO - [Baseline Step 1200/2970] val_ppl=7.66 loss=2.064 time=0.22h peak_mem=8954.7MB\n",
      "2025-05-03 23:43:01,879 - INFO - [Baseline Step 1400/2970] val_ppl=7.70 loss=1.715 time=0.26h peak_mem=8954.7MB\n",
      "2025-05-03 23:43:01,879 - INFO - [Baseline Step 1400/2970] val_ppl=7.70 loss=1.715 time=0.26h peak_mem=8954.7MB\n",
      "2025-05-03 23:43:49,261 - INFO - [Baseline Epoch 1/2] Completed.\n",
      "2025-05-03 23:43:49,261 - INFO - [Baseline Epoch 1/2] Completed.\n",
      "2025-05-03 23:43:49,263 - INFO - [Baseline Epoch 2/2] Starting...\n",
      "2025-05-03 23:43:49,263 - INFO - [Baseline Epoch 2/2] Starting...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d07906b2d94fcca1a1b196315e1aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/1486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 23:45:17,488 - INFO - [Baseline Step 1600/2970] val_ppl=7.57 loss=1.659 time=0.30h peak_mem=8954.7MB\n",
      "2025-05-03 23:45:17,488 - INFO - [Baseline Step 1600/2970] val_ppl=7.57 loss=1.659 time=0.30h peak_mem=8954.7MB\n",
      "2025-05-03 23:47:30,563 - INFO - [Baseline Step 1800/2970] val_ppl=7.61 loss=1.461 time=0.34h peak_mem=8954.7MB\n",
      "2025-05-03 23:47:30,563 - INFO - [Baseline Step 1800/2970] val_ppl=7.61 loss=1.461 time=0.34h peak_mem=8954.7MB\n",
      "2025-05-03 23:49:43,159 - INFO - [Baseline Step 2000/2970] val_ppl=7.58 loss=2.132 time=0.37h peak_mem=8954.7MB\n",
      "2025-05-03 23:49:43,159 - INFO - [Baseline Step 2000/2970] val_ppl=7.58 loss=2.132 time=0.37h peak_mem=8954.7MB\n",
      "2025-05-03 23:51:59,738 - INFO - [Baseline Step 2200/2970] val_ppl=7.70 loss=1.548 time=0.41h peak_mem=8954.7MB\n",
      "2025-05-03 23:51:59,738 - INFO - [Baseline Step 2200/2970] val_ppl=7.70 loss=1.548 time=0.41h peak_mem=8954.7MB\n",
      "2025-05-03 23:54:14,649 - INFO - [Baseline Step 2400/2970] val_ppl=7.58 loss=1.804 time=0.45h peak_mem=8954.7MB\n",
      "2025-05-03 23:54:14,649 - INFO - [Baseline Step 2400/2970] val_ppl=7.58 loss=1.804 time=0.45h peak_mem=8954.7MB\n",
      "2025-05-03 23:56:28,339 - INFO - [Baseline Step 2600/2970] val_ppl=7.54 loss=1.790 time=0.49h peak_mem=8954.7MB\n",
      "2025-05-03 23:56:28,339 - INFO - [Baseline Step 2600/2970] val_ppl=7.54 loss=1.790 time=0.49h peak_mem=8954.7MB\n",
      "2025-05-03 23:58:42,977 - INFO - [Baseline Step 2800/2970] val_ppl=7.58 loss=1.855 time=0.52h peak_mem=8954.7MB\n",
      "2025-05-03 23:58:42,977 - INFO - [Baseline Step 2800/2970] val_ppl=7.58 loss=1.855 time=0.52h peak_mem=8954.7MB\n",
      "2025-05-04 00:00:42,909 - INFO - [Baseline Step 2972/2970] val_ppl=7.57 loss=2.788 time=0.56h peak_mem=8954.7MB\n",
      "2025-05-04 00:00:42,909 - INFO - [Baseline Step 2972/2970] val_ppl=7.57 loss=2.788 time=0.56h peak_mem=8954.7MB\n",
      "2025-05-04 00:00:42,913 - INFO - [Baseline Epoch 2/2] Completed.\n",
      "2025-05-04 00:00:42,913 - INFO - [Baseline Epoch 2/2] Completed.\n",
      "2025-05-04 00:00:42,915 - INFO - --- Finished Baseline ---\n",
      "2025-05-04 00:00:42,915 - INFO - --- Finished Baseline ---\n",
      "2025-05-04 00:00:42,919 - INFO - Baseline results: {'steps': 2972, 'total_hours': 0.5567323772112528, 'peak_mem_mb': 8954.72265625, 'final_ppl': 7.571986464734743, 'steps_log': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, 2972], 'ppl_log': [8.434097353321874, 7.964085477561581, 8.015438834272633, 7.874917716123182, 7.655394625499776, 7.6550593210539635, 7.6984595725537375, 7.5715487579773, 7.608438676773366, 7.5792922948568835, 7.704204131011653, 7.584257780512997, 7.537360730533115, 7.582480859175059, 7.571986464734743]}\n",
      "2025-05-04 00:00:42,919 - INFO - Baseline results: {'steps': 2972, 'total_hours': 0.5567323772112528, 'peak_mem_mb': 8954.72265625, 'final_ppl': 7.571986464734743, 'steps_log': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, 2972], 'ppl_log': [8.434097353321874, 7.964085477561581, 8.015438834272633, 7.874917716123182, 7.655394625499776, 7.6550593210539635, 7.6984595725537375, 7.5715487579773, 7.608438676773366, 7.5792922948568835, 7.704204131011653, 7.584257780512997, 7.537360730533115, 7.582480859175059, 7.571986464734743]}\n",
      "2025-05-04 00:00:43,324 - INFO - \n",
      "===== Starting Standard LoRA Training =====\n",
      "2025-05-04 00:00:43,324 - INFO - \n",
      "===== Starting Standard LoRA Training =====\n",
      "/home/tgs2126/py39_env/lib/python3.9/site-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "2025-05-04 00:00:43,978 - INFO - --- Starting LoRA Standard ---\n",
      "2025-05-04 00:00:43,978 - INFO - --- Starting LoRA Standard ---\n",
      "2025-05-04 00:00:43,980 - INFO - Epochs: 2, LR: 0.0001, Batch Size: 16, Eval Every: 200\n",
      "2025-05-04 00:00:43,980 - INFO - Epochs: 2, LR: 0.0001, Batch Size: 16, Eval Every: 200\n",
      "2025-05-04 00:00:43,983 - INFO - [LoRA Standard Epoch 1/2] Starting...\n",
      "2025-05-04 00:00:43,983 - INFO - [LoRA Standard Epoch 1/2] Starting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.2364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d6ae7a66544fd08808d3805fed3bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/1486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:02:25,169 - INFO - [LoRA Standard Step 200/2970] val_ppl=9.94 loss=1.625 time=0.03h peak_mem=7034.2MB\n",
      "2025-05-04 00:02:25,169 - INFO - [LoRA Standard Step 200/2970] val_ppl=9.94 loss=1.625 time=0.03h peak_mem=7034.2MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:04:05,598 - INFO - [LoRA Standard Step 400/2970] val_ppl=9.05 loss=1.212 time=0.06h peak_mem=7038.3MB\n",
      "2025-05-04 00:04:05,598 - INFO - [LoRA Standard Step 400/2970] val_ppl=9.05 loss=1.212 time=0.06h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:05:47,936 - INFO - [LoRA Standard Step 600/2970] val_ppl=8.73 loss=1.779 time=0.08h peak_mem=7038.3MB\n",
      "2025-05-04 00:05:47,936 - INFO - [LoRA Standard Step 600/2970] val_ppl=8.73 loss=1.779 time=0.08h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:07:29,869 - INFO - [LoRA Standard Step 800/2970] val_ppl=8.52 loss=2.664 time=0.11h peak_mem=7038.3MB\n",
      "2025-05-04 00:07:29,869 - INFO - [LoRA Standard Step 800/2970] val_ppl=8.52 loss=2.664 time=0.11h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:09:11,216 - INFO - [LoRA Standard Step 1000/2970] val_ppl=8.37 loss=2.710 time=0.14h peak_mem=7038.3MB\n",
      "2025-05-04 00:09:11,216 - INFO - [LoRA Standard Step 1000/2970] val_ppl=8.37 loss=2.710 time=0.14h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1000 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:10:53,080 - INFO - [LoRA Standard Step 1200/2970] val_ppl=8.28 loss=2.242 time=0.17h peak_mem=7038.3MB\n",
      "2025-05-04 00:10:53,080 - INFO - [LoRA Standard Step 1200/2970] val_ppl=8.28 loss=2.242 time=0.17h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1200 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:12:36,094 - INFO - [LoRA Standard Step 1400/2970] val_ppl=8.22 loss=1.864 time=0.20h peak_mem=7038.3MB\n",
      "2025-05-04 00:12:36,094 - INFO - [LoRA Standard Step 1400/2970] val_ppl=8.22 loss=1.864 time=0.20h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1400 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:13:08,694 - INFO - [LoRA Standard Epoch 1/2] Completed.\n",
      "2025-05-04 00:13:08,694 - INFO - [LoRA Standard Epoch 1/2] Completed.\n",
      "2025-05-04 00:13:08,697 - INFO - [LoRA Standard Epoch 2/2] Starting...\n",
      "2025-05-04 00:13:08,697 - INFO - [LoRA Standard Epoch 2/2] Starting...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794decabd5f04695ad6028f0da56fb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/1486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:14:18,485 - INFO - [LoRA Standard Step 1600/2970] val_ppl=8.14 loss=1.933 time=0.23h peak_mem=7038.3MB\n",
      "2025-05-04 00:14:18,485 - INFO - [LoRA Standard Step 1600/2970] val_ppl=8.14 loss=1.933 time=0.23h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1600 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:15:59,305 - INFO - [LoRA Standard Step 1800/2970] val_ppl=8.12 loss=1.611 time=0.25h peak_mem=7038.3MB\n",
      "2025-05-04 00:15:59,305 - INFO - [LoRA Standard Step 1800/2970] val_ppl=8.12 loss=1.611 time=0.25h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1800 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:17:40,054 - INFO - [LoRA Standard Step 2000/2970] val_ppl=8.07 loss=2.349 time=0.28h peak_mem=7038.3MB\n",
      "2025-05-04 00:17:40,054 - INFO - [LoRA Standard Step 2000/2970] val_ppl=8.07 loss=2.349 time=0.28h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2000 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:19:23,820 - INFO - [LoRA Standard Step 2200/2970] val_ppl=8.03 loss=1.707 time=0.31h peak_mem=7038.3MB\n",
      "2025-05-04 00:19:23,820 - INFO - [LoRA Standard Step 2200/2970] val_ppl=8.03 loss=1.707 time=0.31h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2200 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:21:06,037 - INFO - [LoRA Standard Step 2400/2970] val_ppl=7.98 loss=1.997 time=0.34h peak_mem=7038.3MB\n",
      "2025-05-04 00:21:06,037 - INFO - [LoRA Standard Step 2400/2970] val_ppl=7.98 loss=1.997 time=0.34h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2400 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:22:47,246 - INFO - [LoRA Standard Step 2600/2970] val_ppl=7.97 loss=2.123 time=0.37h peak_mem=7038.3MB\n",
      "2025-05-04 00:22:47,246 - INFO - [LoRA Standard Step 2600/2970] val_ppl=7.97 loss=2.123 time=0.37h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2600 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:24:29,281 - INFO - [LoRA Standard Step 2800/2970] val_ppl=7.95 loss=2.081 time=0.40h peak_mem=7038.3MB\n",
      "2025-05-04 00:24:29,281 - INFO - [LoRA Standard Step 2800/2970] val_ppl=7.95 loss=2.081 time=0.40h peak_mem=7038.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2800 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:26:01,290 - INFO - [LoRA Standard Step 2972/2970] val_ppl=7.96 loss=3.106 time=0.42h peak_mem=7038.3MB\n",
      "2025-05-04 00:26:01,290 - INFO - [LoRA Standard Step 2972/2970] val_ppl=7.96 loss=3.106 time=0.42h peak_mem=7038.3MB\n",
      "2025-05-04 00:26:01,295 - INFO - [LoRA Standard Epoch 2/2] Completed.\n",
      "2025-05-04 00:26:01,295 - INFO - [LoRA Standard Epoch 2/2] Completed.\n",
      "2025-05-04 00:26:01,297 - INFO - --- Finished LoRA Standard ---\n",
      "2025-05-04 00:26:01,297 - INFO - --- Finished LoRA Standard ---\n",
      "2025-05-04 00:26:01,299 - INFO - Standard LoRA results: {'steps': 2972, 'total_hours': 0.42147751490275065, 'peak_mem_mb': 7038.3125, 'final_ppl': 7.960628080357904, 'steps_log': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, 2972], 'ppl_log': [9.938289279962659, 9.0478709529085, 8.728779189162161, 8.523074540676937, 8.36735088646854, 8.283582189598048, 8.216513981471413, 8.140554892732782, 8.122801834986822, 8.07019809996882, 8.033193045840402, 7.98234689833732, 7.967021497711709, 7.945888859380363, 7.960628080357904]}\n",
      "2025-05-04 00:26:01,299 - INFO - Standard LoRA results: {'steps': 2972, 'total_hours': 0.42147751490275065, 'peak_mem_mb': 7038.3125, 'final_ppl': 7.960628080357904, 'steps_log': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, 2972], 'ppl_log': [9.938289279962659, 9.0478709529085, 8.728779189162161, 8.523074540676937, 8.36735088646854, 8.283582189598048, 8.216513981471413, 8.140554892732782, 8.122801834986822, 8.07019809996882, 8.033193045840402, 7.98234689833732, 7.967021497711709, 7.945888859380363, 7.960628080357904]}\n",
      "2025-05-04 00:26:01,689 - INFO - \n",
      "===== Starting Pre-Training Pruned LoRA Training =====\n",
      "2025-05-04 00:26:01,689 - INFO - \n",
      "===== Starting Pre-Training Pruned LoRA Training =====\n",
      "2025-05-04 00:26:02,404 - INFO - Applying 80.0% pruning BEFORE training...\n",
      "2025-05-04 00:26:02,404 - INFO - Applying 80.0% pruning BEFORE training...\n",
      "2025-05-04 00:26:02,406 - INFO - Identified 24 parameter tensors for pruning.\n",
      "2025-05-04 00:26:02,406 - INFO - Identified 24 parameter tensors for pruning.\n",
      "2025-05-04 00:26:02,413 - INFO - Pruning mask applied. Making pruning permanent...\n",
      "2025-05-04 00:26:02,413 - INFO - Pruning mask applied. Making pruning permanent...\n",
      "2025-05-04 00:26:02,418 - INFO - Removed pruning buffer from 24 modules.\n",
      "2025-05-04 00:26:02,418 - INFO - Removed pruning buffer from 24 modules.\n",
      "2025-05-04 00:26:02,420 - INFO - Pruning made permanent. Calculated sparsity: 80.00%\n",
      "2025-05-04 00:26:02,420 - INFO - Pruning made permanent. Calculated sparsity: 80.00%\n",
      "2025-05-04 00:26:02,421 - INFO - Model pruned before training.\n",
      "2025-05-04 00:26:02,421 - INFO - Model pruned before training.\n",
      "2025-05-04 00:26:02,424 - INFO - --- Starting LoRA Pre-Pruned ---\n",
      "2025-05-04 00:26:02,424 - INFO - --- Starting LoRA Pre-Pruned ---\n",
      "2025-05-04 00:26:02,426 - INFO - Epochs: 2, LR: 0.0001, Batch Size: 16, Eval Every: 200\n",
      "2025-05-04 00:26:02,426 - INFO - Epochs: 2, LR: 0.0001, Batch Size: 16, Eval Every: 200\n",
      "2025-05-04 00:26:02,428 - INFO - [LoRA Pre-Pruned Epoch 1/2] Starting...\n",
      "2025-05-04 00:26:02,428 - INFO - [LoRA Pre-Pruned Epoch 1/2] Starting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.2364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16192d53189449d9085549946cb9d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/1486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2972 that is less than the current step 2973. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:27:43,672 - INFO - [LoRA Pre-Pruned Step 200/2970] val_ppl=10.05 loss=1.651 time=0.03h peak_mem=7521.3MB\n",
      "2025-05-04 00:27:43,672 - INFO - [LoRA Pre-Pruned Step 200/2970] val_ppl=10.05 loss=1.651 time=0.03h peak_mem=7521.3MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:29:23,885 - INFO - [LoRA Pre-Pruned Step 400/2970] val_ppl=9.12 loss=1.207 time=0.06h peak_mem=7523.9MB\n",
      "2025-05-04 00:29:23,885 - INFO - [LoRA Pre-Pruned Step 400/2970] val_ppl=9.12 loss=1.207 time=0.06h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:31:06,242 - INFO - [LoRA Pre-Pruned Step 600/2970] val_ppl=8.80 loss=1.793 time=0.08h peak_mem=7523.9MB\n",
      "2025-05-04 00:31:06,242 - INFO - [LoRA Pre-Pruned Step 600/2970] val_ppl=8.80 loss=1.793 time=0.08h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:32:48,213 - INFO - [LoRA Pre-Pruned Step 800/2970] val_ppl=8.56 loss=2.671 time=0.11h peak_mem=7523.9MB\n",
      "2025-05-04 00:32:48,213 - INFO - [LoRA Pre-Pruned Step 800/2970] val_ppl=8.56 loss=2.671 time=0.11h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:34:29,404 - INFO - [LoRA Pre-Pruned Step 1000/2970] val_ppl=8.41 loss=2.732 time=0.14h peak_mem=7523.9MB\n",
      "2025-05-04 00:34:29,404 - INFO - [LoRA Pre-Pruned Step 1000/2970] val_ppl=8.41 loss=2.732 time=0.14h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1000 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:36:11,529 - INFO - [LoRA Pre-Pruned Step 1200/2970] val_ppl=8.32 loss=2.246 time=0.17h peak_mem=7523.9MB\n",
      "2025-05-04 00:36:11,529 - INFO - [LoRA Pre-Pruned Step 1200/2970] val_ppl=8.32 loss=2.246 time=0.17h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1200 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:37:54,402 - INFO - [LoRA Pre-Pruned Step 1400/2970] val_ppl=8.26 loss=1.869 time=0.20h peak_mem=7523.9MB\n",
      "2025-05-04 00:37:54,402 - INFO - [LoRA Pre-Pruned Step 1400/2970] val_ppl=8.26 loss=1.869 time=0.20h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1400 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:38:27,066 - INFO - [LoRA Pre-Pruned Epoch 1/2] Completed.\n",
      "2025-05-04 00:38:27,066 - INFO - [LoRA Pre-Pruned Epoch 1/2] Completed.\n",
      "2025-05-04 00:38:27,069 - INFO - [LoRA Pre-Pruned Epoch 2/2] Starting...\n",
      "2025-05-04 00:38:27,069 - INFO - [LoRA Pre-Pruned Epoch 2/2] Starting...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c385dffc344a7a98ed2edd0a592a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/1486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:39:37,039 - INFO - [LoRA Pre-Pruned Step 1600/2970] val_ppl=8.17 loss=1.951 time=0.23h peak_mem=7523.9MB\n",
      "2025-05-04 00:39:37,039 - INFO - [LoRA Pre-Pruned Step 1600/2970] val_ppl=8.17 loss=1.951 time=0.23h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1600 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:41:17,896 - INFO - [LoRA Pre-Pruned Step 1800/2970] val_ppl=8.16 loss=1.607 time=0.25h peak_mem=7523.9MB\n",
      "2025-05-04 00:41:17,896 - INFO - [LoRA Pre-Pruned Step 1800/2970] val_ppl=8.16 loss=1.607 time=0.25h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1800 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:42:58,493 - INFO - [LoRA Pre-Pruned Step 2000/2970] val_ppl=8.10 loss=2.341 time=0.28h peak_mem=7523.9MB\n",
      "2025-05-04 00:42:58,493 - INFO - [LoRA Pre-Pruned Step 2000/2970] val_ppl=8.10 loss=2.341 time=0.28h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2000 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:44:42,113 - INFO - [LoRA Pre-Pruned Step 2200/2970] val_ppl=8.06 loss=1.698 time=0.31h peak_mem=7523.9MB\n",
      "2025-05-04 00:44:42,113 - INFO - [LoRA Pre-Pruned Step 2200/2970] val_ppl=8.06 loss=1.698 time=0.31h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2200 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:46:24,394 - INFO - [LoRA Pre-Pruned Step 2400/2970] val_ppl=8.01 loss=2.016 time=0.34h peak_mem=7523.9MB\n",
      "2025-05-04 00:46:24,394 - INFO - [LoRA Pre-Pruned Step 2400/2970] val_ppl=8.01 loss=2.016 time=0.34h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2400 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:48:05,559 - INFO - [LoRA Pre-Pruned Step 2600/2970] val_ppl=8.01 loss=2.140 time=0.37h peak_mem=7523.9MB\n",
      "2025-05-04 00:48:05,559 - INFO - [LoRA Pre-Pruned Step 2600/2970] val_ppl=8.01 loss=2.140 time=0.37h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2600 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:49:47,652 - INFO - [LoRA Pre-Pruned Step 2800/2970] val_ppl=7.98 loss=2.085 time=0.40h peak_mem=7523.9MB\n",
      "2025-05-04 00:49:47,652 - INFO - [LoRA Pre-Pruned Step 2800/2970] val_ppl=7.98 loss=2.085 time=0.40h peak_mem=7523.9MB\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2800 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "2025-05-04 00:51:19,605 - INFO - [LoRA Pre-Pruned Step 2972/2970] val_ppl=7.99 loss=3.100 time=0.42h peak_mem=7523.9MB\n",
      "2025-05-04 00:51:19,605 - INFO - [LoRA Pre-Pruned Step 2972/2970] val_ppl=7.99 loss=3.100 time=0.42h peak_mem=7523.9MB\n",
      "2025-05-04 00:51:19,609 - INFO - [LoRA Pre-Pruned Epoch 2/2] Completed.\n",
      "2025-05-04 00:51:19,609 - INFO - [LoRA Pre-Pruned Epoch 2/2] Completed.\n",
      "2025-05-04 00:51:19,611 - INFO - --- Finished LoRA Pre-Pruned ---\n",
      "2025-05-04 00:51:19,611 - INFO - --- Finished LoRA Pre-Pruned ---\n",
      "2025-05-04 00:51:19,613 - INFO - Pre-Training Pruned LoRA results: {'steps': 2972, 'total_hours': 0.4214407371150123, 'peak_mem_mb': 7523.90625, 'final_ppl': 7.989143300047097, 'steps_log': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, 2972], 'ppl_log': [10.04987631708983, 9.124553740286695, 8.79572997503477, 8.564474569467464, 8.410780879551423, 8.318819756332887, 8.261473216323079, 8.173423237387896, 8.159589860623374, 8.099319048457835, 8.06036155295874, 8.011017176399093, 8.006701385313642, 7.982618223715242, 7.989143300047097]}\n",
      "2025-05-04 00:51:19,613 - INFO - Pre-Training Pruned LoRA results: {'steps': 2972, 'total_hours': 0.4214407371150123, 'peak_mem_mb': 7523.90625, 'final_ppl': 7.989143300047097, 'steps_log': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, 2972], 'ppl_log': [10.04987631708983, 9.124553740286695, 8.79572997503477, 8.564474569467464, 8.410780879551423, 8.318819756332887, 8.261473216323079, 8.173423237387896, 8.159589860623374, 8.099319048457835, 8.06036155295874, 8.011017176399093, 8.006701385313642, 7.982618223715242, 7.989143300047097]}\n",
      "2025-05-04 00:51:19,993 - INFO - \n",
      "===== Starting Inference Benchmarks =====\n",
      "2025-05-04 00:51:19,993 - INFO - \n",
      "===== Starting Inference Benchmarks =====\n",
      "2025-05-04 00:51:19,994 - INFO - --- Benchmarking Inference for: Baseline ---\n",
      "2025-05-04 00:51:19,994 - INFO - --- Benchmarking Inference for: Baseline ---\n",
      "2025-05-04 00:51:19,997 - INFO - --- Starting Inference Benchmark (Generation: False) ---\n",
      "2025-05-04 00:51:19,997 - INFO - --- Starting Inference Benchmark (Generation: False) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2d86abd27e405eb9d6b3a2310a70d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:51:23,848 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:23,848 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:23,851 - INFO - --- Starting Inference Benchmark (Generation: True) ---\n",
      "2025-05-04 00:51:23,851 - INFO - --- Starting Inference Benchmark (Generation: True) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29d03be89f245688c91331adab0b867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2972 that is less than the current step 2974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "2025-05-04 00:51:27,033 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:27,033 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:27,035 - INFO - Inference Results for Baseline: Fwd Latency=8.92ms, Gen Latency=15.04ms\n",
      "2025-05-04 00:51:27,035 - INFO - Inference Results for Baseline: Fwd Latency=8.92ms, Gen Latency=15.04ms\n",
      "2025-05-04 00:51:27,307 - INFO - --- Benchmarking Inference for: LoRA Standard ---\n",
      "2025-05-04 00:51:27,307 - INFO - --- Benchmarking Inference for: LoRA Standard ---\n",
      "2025-05-04 00:51:27,310 - INFO - --- Starting Inference Benchmark (Generation: False) ---\n",
      "2025-05-04 00:51:27,310 - INFO - --- Starting Inference Benchmark (Generation: False) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31eced0ceb4b4a4880b0f988399e29a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:51:31,309 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:31,309 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:31,313 - INFO - --- Starting Inference Benchmark (Generation: True) ---\n",
      "2025-05-04 00:51:31,313 - INFO - --- Starting Inference Benchmark (Generation: True) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9b876ab29d4be6ba96289c835381ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "2025-05-04 00:51:34,213 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:34,213 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:34,215 - INFO - Inference Results for LoRA Standard: Fwd Latency=9.28ms, Gen Latency=13.62ms\n",
      "2025-05-04 00:51:34,215 - INFO - Inference Results for LoRA Standard: Fwd Latency=9.28ms, Gen Latency=13.62ms\n",
      "2025-05-04 00:51:34,492 - INFO - --- Benchmarking Inference for: LoRA Pre-Pruned ---\n",
      "2025-05-04 00:51:34,492 - INFO - --- Benchmarking Inference for: LoRA Pre-Pruned ---\n",
      "2025-05-04 00:51:34,495 - INFO - --- Starting Inference Benchmark (Generation: False) ---\n",
      "2025-05-04 00:51:34,495 - INFO - --- Starting Inference Benchmark (Generation: False) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa48c7570054a1d9a7f68472a54357c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:51:38,498 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:38,498 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:38,501 - INFO - --- Starting Inference Benchmark (Generation: True) ---\n",
      "2025-05-04 00:51:38,501 - INFO - --- Starting Inference Benchmark (Generation: True) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19eccf9c1b1d4871b2bb31631fd281a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "2025-05-04 00:51:41,384 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:41,384 - INFO - --- Finished Inference Benchmark ---\n",
      "2025-05-04 00:51:41,385 - INFO - Inference Results for LoRA Pre-Pruned: Fwd Latency=9.28ms, Gen Latency=13.55ms\n",
      "2025-05-04 00:51:41,385 - INFO - Inference Results for LoRA Pre-Pruned: Fwd Latency=9.28ms, Gen Latency=13.55ms\n",
      "2025-05-04 00:51:41,664 - INFO - \n",
      "===== Generating Learning Curve Plot =====\n",
      "2025-05-04 00:51:41,664 - INFO - \n",
      "===== Generating Learning Curve Plot =====\n",
      "2025-05-04 00:51:41,947 - INFO - Learning curve plot logged to Weights & Biases.\n",
      "2025-05-04 00:51:41,947 - INFO - Learning curve plot logged to Weights & Biases.\n",
      "2025-05-04 00:51:41,949 - INFO - \n",
      "===== Final Benchmark Comparison =====\n",
      "2025-05-04 00:51:41,949 - INFO - \n",
      "===== Final Benchmark Comparison =====\n",
      "2025-05-04 00:51:41,958 - INFO - \n",
      "Comparison DataFrame:\n",
      "                      Total Steps Total Hours (h) Peak GPU Mem (MB) Final Val PPL Fwd Latency (ms) Fwd TP (samples/s) Gen Latency (ms) Gen TP (samples/s)\n",
      "Baseline                    2,972            0.56           8,954.7          7.57              8.9              112.1             15.0               66.5\n",
      "LoRA Standard               2,972            0.42           7,038.3          7.96              9.3              107.7             13.6               73.4\n",
      "LoRA Pre-Pruned (80%)       2,972            0.42           7,523.9          7.99              9.3              107.7             13.5               73.8\n",
      "2025-05-04 00:51:41,958 - INFO - \n",
      "Comparison DataFrame:\n",
      "                      Total Steps Total Hours (h) Peak GPU Mem (MB) Final Val PPL Fwd Latency (ms) Fwd TP (samples/s) Gen Latency (ms) Gen TP (samples/s)\n",
      "Baseline                    2,972            0.56           8,954.7          7.57              8.9              112.1             15.0               66.5\n",
      "LoRA Standard               2,972            0.42           7,038.3          7.96              9.3              107.7             13.6               73.4\n",
      "LoRA Pre-Pruned (80%)       2,972            0.42           7,523.9          7.99              9.3              107.7             13.5               73.8\n",
      "2025-05-04 00:51:42,152 - INFO - Comparison table logged to Weights & Biases.\n",
      "2025-05-04 00:51:42,152 - INFO - Comparison table logged to Weights & Biases.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Baseline/Current Peak Mem MB</td><td>▁▁▁▁▁██████████</td></tr><tr><td>Baseline/Elapsed Hours</td><td>▁▁▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>Baseline/Loss</td><td>▃▁▄▇▇▅▄▃▃▅▃▄▄▄█</td></tr><tr><td>Baseline/Step</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>Baseline/Val Perplexity</td><td>█▄▅▄▂▂▂▁▂▁▂▁▁▁▁</td></tr><tr><td>Summary/Baseline/Fwd Pass Latency ms</td><td>▁</td></tr><tr><td>Summary/Baseline/Fwd Pass Throughput</td><td>▁</td></tr><tr><td>Summary/Baseline/Gen Latency ms</td><td>▁</td></tr><tr><td>Summary/Baseline/Gen Throughput</td><td>▁</td></tr><tr><td>Summary/Baseline/final_ppl</td><td>▁</td></tr><tr><td>Summary/Baseline/peak_mem_mb</td><td>▁</td></tr><tr><td>Summary/Baseline/steps</td><td>▁</td></tr><tr><td>Summary/Baseline/total_hours</td><td>▁</td></tr><tr><td>Summary/LoRA Pre-Pruned/Fwd Pass Latency ms</td><td>▁</td></tr><tr><td>Summary/LoRA Pre-Pruned/Fwd Pass Throughput</td><td>▁</td></tr><tr><td>Summary/LoRA Pre-Pruned/Gen Latency ms</td><td>▁</td></tr><tr><td>Summary/LoRA Pre-Pruned/Gen Throughput</td><td>▁</td></tr><tr><td>Summary/LoRA Standard/Fwd Pass Latency ms</td><td>▁</td></tr><tr><td>Summary/LoRA Standard/Fwd Pass Throughput</td><td>▁</td></tr><tr><td>Summary/LoRA Standard/Gen Latency ms</td><td>▁</td></tr><tr><td>Summary/LoRA Standard/Gen Throughput</td><td>▁</td></tr><tr><td>Summary/Pre-Pruned LoRA (80%)/final_ppl</td><td>▁</td></tr><tr><td>Summary/Pre-Pruned LoRA (80%)/peak_mem_mb</td><td>▁</td></tr><tr><td>Summary/Pre-Pruned LoRA (80%)/steps</td><td>▁</td></tr><tr><td>Summary/Pre-Pruned LoRA (80%)/total_hours</td><td>▁</td></tr><tr><td>Summary/Standard LoRA/final_ppl</td><td>▁</td></tr><tr><td>Summary/Standard LoRA/peak_mem_mb</td><td>▁</td></tr><tr><td>Summary/Standard LoRA/steps</td><td>▁</td></tr><tr><td>Summary/Standard LoRA/total_hours</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Baseline/Current Peak Mem MB</td><td>8954.72266</td></tr><tr><td>Baseline/Elapsed Hours</td><td>0.55673</td></tr><tr><td>Baseline/Loss</td><td>2.78849</td></tr><tr><td>Baseline/Step</td><td>2972</td></tr><tr><td>Baseline/Val Perplexity</td><td>7.57199</td></tr><tr><td>Summary/Baseline/Fwd Pass Latency ms</td><td>8.92146</td></tr><tr><td>Summary/Baseline/Fwd Pass Throughput</td><td>112.08927</td></tr><tr><td>Summary/Baseline/Gen Latency ms</td><td>15.03577</td></tr><tr><td>Summary/Baseline/Gen Throughput</td><td>66.50805</td></tr><tr><td>Summary/Baseline/final_ppl</td><td>7.57199</td></tr><tr><td>Summary/Baseline/peak_mem_mb</td><td>8954.72266</td></tr><tr><td>Summary/Baseline/steps</td><td>2972</td></tr><tr><td>Summary/Baseline/total_hours</td><td>0.55673</td></tr><tr><td>Summary/LoRA Pre-Pruned/Fwd Pass Latency ms</td><td>9.28271</td></tr><tr><td>Summary/LoRA Pre-Pruned/Fwd Pass Throughput</td><td>107.72719</td></tr><tr><td>Summary/LoRA Pre-Pruned/Gen Latency ms</td><td>13.54914</td></tr><tr><td>Summary/LoRA Pre-Pruned/Gen Throughput</td><td>73.80543</td></tr><tr><td>Summary/LoRA Standard/Fwd Pass Latency ms</td><td>9.28417</td></tr><tr><td>Summary/LoRA Standard/Fwd Pass Throughput</td><td>107.7102</td></tr><tr><td>Summary/LoRA Standard/Gen Latency ms</td><td>13.61976</td></tr><tr><td>Summary/LoRA Standard/Gen Throughput</td><td>73.42275</td></tr><tr><td>Summary/Pre-Pruned LoRA (80%)/final_ppl</td><td>7.98914</td></tr><tr><td>Summary/Pre-Pruned LoRA (80%)/peak_mem_mb</td><td>7523.90625</td></tr><tr><td>Summary/Pre-Pruned LoRA (80%)/steps</td><td>2972</td></tr><tr><td>Summary/Pre-Pruned LoRA (80%)/total_hours</td><td>0.42144</td></tr><tr><td>Summary/Standard LoRA/final_ppl</td><td>7.96063</td></tr><tr><td>Summary/Standard LoRA/peak_mem_mb</td><td>7038.3125</td></tr><tr><td>Summary/Standard LoRA/steps</td><td>2972</td></tr><tr><td>Summary/Standard LoRA/total_hours</td><td>0.42148</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Baseline_vs_LoRA_vs_Pruned_2Ep_80%</strong> at: <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison-final/runs/5ws5df62' target=\"_blank\">https://wandb.ai/hpml_final_project/lora-pruning-comparison-final/runs/5ws5df62</a><br> View project at: <a href='https://wandb.ai/hpml_final_project/lora-pruning-comparison-final' target=\"_blank\">https://wandb.ai/hpml_final_project/lora-pruning-comparison-final</a><br>Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250503_232712-5ws5df62/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:51:44,204 - INFO - Weights & Biases run finished.\n",
      "2025-05-04 00:51:44,204 - INFO - Weights & Biases run finished.\n",
      "2025-05-04 00:51:44,205 - INFO - \n",
      "===== Script Finished =====\n",
      "2025-05-04 00:51:44,205 - INFO - \n",
      "===== Script Finished =====\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time, math, logging\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GenerationConfig\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft.tuners.lora import LoraLayer\n",
    "import torch.nn.utils.prune as prune\n",
    "import pandas as pd\n",
    "import gc\n",
    "import copy\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "max_length = 128\n",
    "num_train_epochs = 2\n",
    "eval_every_steps = 200\n",
    "batch_size = 16\n",
    "inference_batch_size = 8\n",
    "num_inference_batches = 50\n",
    "pruning_amount = 0.8\n",
    "lora_r = 8\n",
    "lora_alpha = 32\n",
    "lora_target_modules = [\"c_attn\"]\n",
    "baseline_lr = 5e-5\n",
    "lora_lr = 1e-4\n",
    "run_inference_benchmark = True\n",
    "\n",
    "try:\n",
    "    run = wandb.init(\n",
    "        project=\"lora-pruning-comparison-final\",\n",
    "        name=f\"Baseline_vs_LoRA_vs_Pruned_{num_train_epochs}Ep_{pruning_amount:.0%}\",\n",
    "        config={\n",
    "            \"model_name\": model_name, \"max_length\": max_length,\n",
    "            \"num_train_epochs\": num_train_epochs, \"batch_size\": batch_size,\n",
    "            \"pruning_amount\": pruning_amount, \"lora_r\": lora_r,\n",
    "            \"lora_alpha\": lora_alpha, \"lora_target_modules\": lora_target_modules,\n",
    "            \"baseline_lr\": baseline_lr, \"lora_lr\": lora_lr,\n",
    "            \"eval_every_steps\": eval_every_steps, \"device\": str(device),\n",
    "            \"inference_batch_size\": inference_batch_size,\n",
    "            \"num_inference_batches\": num_inference_batches,\n",
    "            \"run_inference_benchmark\": run_inference_benchmark\n",
    "        }\n",
    "    )\n",
    "    logger.info(\"Weights & Biases initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to initialize Weights & Biases: {e}\")\n",
    "    run = None\n",
    "\n",
    "logger.info(\"Loading data...\")\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_texts_full = [t for t in dataset[\"train\"][\"text\"] if t.strip()]\n",
    "val_texts_full = [t for t in dataset[\"validation\"][\"text\"] if t.strip()]\n",
    "test_texts_full = val_texts_full[:inference_batch_size * num_inference_batches]\n",
    "logger.info(f\"Data loaded. Train: {len(train_texts_full)}, Val/Test: {len(val_texts_full)}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_perplexity(model, tokenizer, texts, device, batch_size=8, max_length=128):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    total_evaluated = 0\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        if not batch: continue\n",
    "        total_evaluated += len(batch)\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs, labels=inputs.input_ids)\n",
    "        if hasattr(outputs, 'loss') and outputs.loss is not None:\n",
    "            losses.append(outputs.loss.item() * len(batch))\n",
    "    if not losses or total_evaluated == 0: return float('inf')\n",
    "    avg_loss = sum(losses) / total_evaluated\n",
    "    if avg_loss <= 0: return float('inf')\n",
    "    return math.exp(avg_loss)\n",
    "\n",
    "def train_fixed_duration(model, tokenizer, train_texts, val_texts, num_epochs,\n",
    "                         device, lr=5e-5, batch_size=8, max_length=128,\n",
    "                         eval_every=500, run_label=\"Training\"):\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    start_time = time.time()\n",
    "    peak_mem_overall = 0\n",
    "\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "    total_expected_steps = (len(train_texts) // batch_size) * num_epochs\n",
    "    step = 0\n",
    "    all_val_ppl = []\n",
    "    steps_log = []\n",
    "\n",
    "    logger.info(f\"--- Starting {run_label} ---\")\n",
    "    logger.info(f\"Epochs: {num_epochs}, LR: {lr}, Batch Size: {batch_size}, Eval Every: {eval_every}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        logger.info(f\"[{run_label} Epoch {epoch+1}/{num_epochs}] Starting...\")\n",
    "        progress_bar = tqdm(range(0, len(train_texts), batch_size), desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "        for i in progress_bar:\n",
    "            batch = train_texts[i:i+batch_size]\n",
    "            if not batch: continue\n",
    "\n",
    "            inputs = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "            outputs = model(**inputs, labels=inputs.input_ids)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            if loss is None or torch.isnan(loss):\n",
    "                logger.warning(f\"[{run_label} Step {step}] Loss is None or NaN. Skipping step.\")\n",
    "                step += 1\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            step += 1\n",
    "\n",
    "            progress_bar.set_postfix({'loss': f\"{loss.item():.3f}\"})\n",
    "\n",
    "            is_last_batch_overall = (epoch == num_epochs - 1 and i + batch_size >= len(train_texts))\n",
    "            if step % eval_every == 0 or is_last_batch_overall:\n",
    "                current_loss_val = loss.item() if loss is not None else float('nan')\n",
    "                val_ppl = compute_perplexity(model, tokenizer, val_texts, device, batch_size=batch_size, max_length=max_length)\n",
    "                if not math.isinf(val_ppl) and not math.isnan(val_ppl):\n",
    "                    all_val_ppl.append(val_ppl)\n",
    "                    steps_log.append(step)\n",
    "\n",
    "                elapsed_h = (time.time() - start_time) / 3600\n",
    "                current_peak_mem = 0\n",
    "                if device == torch.device(\"cuda\"):\n",
    "                    current_peak_mem = torch.cuda.max_memory_allocated(device) / 1024**2\n",
    "                    peak_mem_overall = max(peak_mem_overall, current_peak_mem)\n",
    "\n",
    "                logger.info(f\"[{run_label} Step {step}/{total_expected_steps}] val_ppl={val_ppl:.2f} loss={current_loss_val:.3f} time={elapsed_h:.2f}h peak_mem={current_peak_mem:.1f}MB\")\n",
    "\n",
    "                if run:\n",
    "                     wandb.log({\n",
    "                         f\"{run_label}/Step\": step, f\"{run_label}/Val Perplexity\": val_ppl,\n",
    "                         f\"{run_label}/Loss\": current_loss_val, f\"{run_label}/Elapsed Hours\": elapsed_h,\n",
    "                         f\"{run_label}/Current Peak Mem MB\": current_peak_mem\n",
    "                     }, step=step)\n",
    "                model.train()\n",
    "\n",
    "        logger.info(f\"[{run_label} Epoch {epoch+1}/{num_epochs}] Completed.\")\n",
    "\n",
    "    total_h = (time.time() - start_time) / 3600\n",
    "    final_mem = peak_mem_overall\n",
    "    final_ppl = all_val_ppl[-1] if all_val_ppl else float('inf')\n",
    "\n",
    "    logger.info(f\"--- Finished {run_label} ---\")\n",
    "    return {\n",
    "        \"steps\": step, \"total_hours\": total_h, \"peak_mem_mb\": final_mem,\n",
    "        \"final_ppl\": final_ppl, \"steps_log\": steps_log, \"ppl_log\": all_val_ppl\n",
    "    }\n",
    "\n",
    "def apply_pruning(model_to_prune, amount):\n",
    "    parameters_to_prune = []\n",
    "    target_modules = set()\n",
    "    logger.debug(\"Starting parameter search for pruning...\")\n",
    "    for name, module in model_to_prune.named_modules():\n",
    "         if isinstance(module, LoraLayer):\n",
    "             logger.debug(f\"Found LoraLayer: {name}\")\n",
    "             for key in ['lora_A', 'lora_B']:\n",
    "                if hasattr(module, key):\n",
    "                    sub_module_dict = getattr(module, key)\n",
    "                    if isinstance(sub_module_dict, torch.nn.ModuleDict):\n",
    "                         for adapter_name, sub_module in sub_module_dict.items():\n",
    "                             if hasattr(sub_module, 'weight'):\n",
    "                                logger.debug(f\"   Found weight in {key}.{adapter_name}. Adding.\")\n",
    "                                parameters_to_prune.append((sub_module, 'weight'))\n",
    "                                target_modules.add(sub_module)\n",
    "                    elif isinstance(sub_module_dict, torch.nn.Module):\n",
    "                        if hasattr(sub_module_dict, 'weight'):\n",
    "                            logger.debug(f\"   Found weight directly in {key}. Adding.\")\n",
    "                            parameters_to_prune.append((sub_module_dict, 'weight'))\n",
    "                            target_modules.add(sub_module_dict)\n",
    "\n",
    "    if not parameters_to_prune:\n",
    "        logger.warning(\"Could not find any LoRA parameters to prune!\")\n",
    "        return 0.0\n",
    "    else:\n",
    "        logger.info(f\"Identified {len(parameters_to_prune)} parameter tensors for pruning.\")\n",
    "        prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=amount)\n",
    "        logger.info(\"Pruning mask applied. Making pruning permanent...\")\n",
    "        final_total_params = 0; final_zero_params = 0; pruned_module_count = 0\n",
    "        for module in target_modules:\n",
    "            is_currently_pruned = prune.is_pruned(module)\n",
    "            if is_currently_pruned:\n",
    "                 try:\n",
    "                     mask = getattr(module, 'weight_mask', None); orig_param = getattr(module, 'weight_orig', None)\n",
    "                     if mask is not None and orig_param is not None:\n",
    "                          param_element_count = orig_param.nelement(); param_zero_count = torch.sum(mask == 0).item()\n",
    "                          final_total_params += param_element_count; final_zero_params += param_zero_count\n",
    "                     elif hasattr(module, 'weight'):\n",
    "                          param = getattr(module, 'weight'); final_total_params += param.nelement(); final_zero_params += torch.sum(param == 0).item()\n",
    "                 except AttributeError:\n",
    "                       if hasattr(module, 'weight'):\n",
    "                           param = getattr(module, 'weight'); final_total_params += param.nelement(); final_zero_params += torch.sum(param == 0).item()\n",
    "                 prune.remove(module, 'weight'); pruned_module_count += 1\n",
    "            elif hasattr(module, 'weight'):\n",
    "                 param = getattr(module, 'weight'); final_total_params += param.nelement()\n",
    "        logger.info(f\"Removed pruning buffer from {pruned_module_count} modules.\")\n",
    "        if final_total_params > 0:\n",
    "            final_sparsity = 100. * float(final_zero_params) / float(final_total_params)\n",
    "            logger.info(f\"Pruning made permanent. Calculated sparsity: {final_sparsity:.2f}%\")\n",
    "            return final_sparsity\n",
    "        else:\n",
    "            logger.info(\"Pruning made permanent (no parameters found or counted).\"); return 0.0\n",
    "\n",
    "@torch.no_grad()\n",
    "def benchmark_inference(model, tokenizer, texts, device, batch_size=8, max_length=128, num_batches=50, generation=False):\n",
    "    model.eval()\n",
    "    latencies = []\n",
    "    total_samples = 0\n",
    "    logger.info(f\"--- Starting Inference Benchmark (Generation: {generation}) ---\")\n",
    "    generation_config = GenerationConfig(max_new_tokens=5, pad_token_id=tokenizer.pad_token_id) if generation else None\n",
    "\n",
    "    for i in tqdm(range(0, min(len(texts), batch_size * num_batches), batch_size), desc=\"Inference\", leave=False):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        if not batch: continue\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "        batch_samples = inputs['input_ids'].shape[0]\n",
    "        total_samples += batch_samples\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        if generation:\n",
    "            _ = model.generate(**inputs, generation_config=generation_config)\n",
    "        else:\n",
    "            _ = model(**inputs)\n",
    "        if device == torch.device(\"cuda\"): torch.cuda.synchronize()\n",
    "        end_time = time.perf_counter()\n",
    "        latencies.append(end_time - start_time)\n",
    "\n",
    "    avg_latency_batch = np.mean(latencies) if latencies else 0\n",
    "    throughput_samples_sec = total_samples / sum(latencies) if latencies else 0\n",
    "    avg_latency_sample = (sum(latencies) / total_samples) * 1000 if total_samples > 0 else 0\n",
    "\n",
    "    logger.info(f\"--- Finished Inference Benchmark ---\")\n",
    "    return {\n",
    "        \"avg_inference_latency_ms_per_sample\": avg_latency_sample,\n",
    "        \"avg_inference_throughput_samples_sec\": throughput_samples_sec\n",
    "    }\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=lora_r, lora_alpha=lora_alpha, target_modules=lora_target_modules,\n",
    "    lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "all_results = {}\n",
    "trained_models = {}\n",
    "\n",
    "logger.info(\"\\n===== Starting Baseline Full Fine-tune Training =====\")\n",
    "model_baseline = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "for p in model_baseline.parameters(): p.requires_grad = True\n",
    "logger.info(f\"Trainable params (Baseline): {sum(p.numel() for p in model_baseline.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "baseline_res = train_fixed_duration(\n",
    "    model_baseline, tokenizer, train_texts_full, val_texts_full, num_epochs=num_train_epochs,\n",
    "    device=device, lr=baseline_lr, batch_size=batch_size, max_length=max_length,\n",
    "    eval_every=eval_every_steps, run_label=\"Baseline\"\n",
    ")\n",
    "logger.info(f\"Baseline results: {baseline_res}\")\n",
    "if 'final_ppl' in baseline_res: all_results[\"Baseline\"] = baseline_res\n",
    "if run and 'final_ppl' in baseline_res: wandb.log({f\"Summary/Baseline/{k}\": v for k, v in baseline_res.items() if 'log' not in k})\n",
    "if 'final_ppl' in baseline_res: trained_models[\"Baseline\"] = copy.deepcopy(model_baseline)\n",
    "\n",
    "del model_baseline; gc.collect(); torch.cuda.empty_cache() if device == torch.device(\"cuda\") else None\n",
    "\n",
    "logger.info(\"\\n===== Starting Standard LoRA Training =====\")\n",
    "base_model_std = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "for param in base_model_std.parameters(): param.requires_grad = False\n",
    "lora_model_std = get_peft_model(base_model_std, lora_cfg)\n",
    "lora_model_std.print_trainable_parameters()\n",
    "\n",
    "lora_std_res = train_fixed_duration(\n",
    "    lora_model_std, tokenizer, train_texts_full, val_texts_full, num_epochs=num_train_epochs,\n",
    "    device=device, lr=lora_lr, batch_size=batch_size, max_length=max_length,\n",
    "    eval_every=eval_every_steps, run_label=\"LoRA Standard\"\n",
    ")\n",
    "logger.info(f\"Standard LoRA results: {lora_std_res}\")\n",
    "if 'final_ppl' in lora_std_res: all_results[\"LoRA Standard\"] = lora_std_res\n",
    "if run and 'final_ppl' in lora_std_res: wandb.log({f\"Summary/Standard LoRA/{k}\": v for k, v in lora_std_res.items() if 'log' not in k})\n",
    "if 'final_ppl' in lora_std_res: trained_models[\"LoRA Standard\"] = copy.deepcopy(lora_model_std)\n",
    "\n",
    "del base_model_std, lora_model_std; gc.collect(); torch.cuda.empty_cache() if device == torch.device(\"cuda\") else None\n",
    "\n",
    "logger.info(\"\\n===== Starting Pre-Training Pruned LoRA Training =====\")\n",
    "base_model_pre_prune = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "for param in base_model_pre_prune.parameters(): param.requires_grad = False\n",
    "lora_model_pre_prune = get_peft_model(base_model_pre_prune, lora_cfg)\n",
    "lora_model_pre_prune.print_trainable_parameters()\n",
    "\n",
    "logger.info(f\"Applying {pruning_amount:.1%} pruning BEFORE training...\")\n",
    "apply_pruning(lora_model_pre_prune, pruning_amount)\n",
    "logger.info(\"Model pruned before training.\")\n",
    "\n",
    "lora_pre_prune_res = train_fixed_duration(\n",
    "    lora_model_pre_prune, tokenizer, train_texts_full, val_texts_full, num_epochs=num_train_epochs,\n",
    "    device=device, lr=lora_lr, batch_size=batch_size, max_length=max_length,\n",
    "    eval_every=eval_every_steps, run_label=\"LoRA Pre-Pruned\"\n",
    ")\n",
    "logger.info(f\"Pre-Training Pruned LoRA results: {lora_pre_prune_res}\")\n",
    "if 'final_ppl' in lora_pre_prune_res: all_results[\"LoRA Pre-Pruned\"] = lora_pre_prune_res\n",
    "if run and 'final_ppl' in lora_pre_prune_res: wandb.log({f\"Summary/Pre-Pruned LoRA ({pruning_amount:.0%})/{k}\": v for k, v in lora_pre_prune_res.items() if 'log' not in k})\n",
    "if 'final_ppl' in lora_pre_prune_res: trained_models[\"LoRA Pre-Pruned\"] = copy.deepcopy(lora_model_pre_prune)\n",
    "\n",
    "del base_model_pre_prune, lora_model_pre_prune; gc.collect(); torch.cuda.empty_cache() if device == torch.device(\"cuda\") else None\n",
    "\n",
    "if run_inference_benchmark:\n",
    "    logger.info(\"\\n===== Starting Inference Benchmarks =====\")\n",
    "    for label, model in trained_models.items():\n",
    "        if model is not None:\n",
    "            logger.info(f\"--- Benchmarking Inference for: {label} ---\")\n",
    "            inference_res_fwd = benchmark_inference(\n",
    "                model, tokenizer, test_texts_full, device,\n",
    "                batch_size=inference_batch_size, max_length=max_length,\n",
    "                num_batches=num_inference_batches, generation=False\n",
    "            )\n",
    "            inference_res_gen = benchmark_inference(\n",
    "                model, tokenizer, test_texts_full, device,\n",
    "                batch_size=inference_batch_size, max_length=max_length,\n",
    "                num_batches=num_inference_batches // 2,\n",
    "                generation=True\n",
    "            )\n",
    "            all_results[label].update({\n",
    "                 \"fwd_pass_latency_ms\": inference_res_fwd[\"avg_inference_latency_ms_per_sample\"],\n",
    "                 \"fwd_pass_throughput\": inference_res_fwd[\"avg_inference_throughput_samples_sec\"],\n",
    "                 \"gen_latency_ms\": inference_res_gen[\"avg_inference_latency_ms_per_sample\"],\n",
    "                 \"gen_throughput\": inference_res_gen[\"avg_inference_throughput_samples_sec\"]\n",
    "            })\n",
    "            logger.info(f\"Inference Results for {label}: Fwd Latency={inference_res_fwd['avg_inference_latency_ms_per_sample']:.2f}ms, Gen Latency={inference_res_gen['avg_inference_latency_ms_per_sample']:.2f}ms\")\n",
    "            if run:\n",
    "                wandb.log({\n",
    "                    f\"Summary/{label}/Fwd Pass Latency ms\": inference_res_fwd[\"avg_inference_latency_ms_per_sample\"],\n",
    "                    f\"Summary/{label}/Fwd Pass Throughput\": inference_res_fwd[\"avg_inference_throughput_samples_sec\"],\n",
    "                    f\"Summary/{label}/Gen Latency ms\": inference_res_gen[\"avg_inference_latency_ms_per_sample\"],\n",
    "                    f\"Summary/{label}/Gen Throughput\": inference_res_gen[\"avg_inference_throughput_samples_sec\"]\n",
    "                })\n",
    "        else:\n",
    "            logger.warning(f\"Skipping inference benchmark for {label} as training failed.\")\n",
    "        if model is not None: del model\n",
    "        gc.collect(); torch.cuda.empty_cache() if device == torch.device(\"cuda\") else None\n",
    "    trained_models = {}\n",
    "\n",
    "logger.info(\"\\n===== Generating Learning Curve Plot =====\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_data_logged = False\n",
    "for label, results in all_results.items():\n",
    "    if \"steps_log\" in results and \"ppl_log\" in results and results[\"steps_log\"] and results[\"ppl_log\"]:\n",
    "        steps_axis = np.array(results[\"steps_log\"])\n",
    "        ppl_values = np.array(results[\"ppl_log\"])\n",
    "        mask = np.isfinite(ppl_values)\n",
    "        if np.any(mask):\n",
    "             plt.plot(steps_axis[mask], ppl_values[mask], marker='.', linestyle='-', label=label)\n",
    "             plot_data_logged = True\n",
    "        else:\n",
    "             logger.warning(f\"No valid PPL data points to plot for {label}.\")\n",
    "\n",
    "if plot_data_logged:\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Validation Perplexity\")\n",
    "    plt.title(\"Perplexity vs. Training Steps\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    min_ppl_overall = min(min(r[\"ppl_log\"]) for r in all_results.values() if r and r.get(\"ppl_log\")) if any(r and r.get(\"ppl_log\") for r in all_results.values()) else 7\n",
    "    plt.ylim(bottom=max(5, min(min_ppl_overall - 0.5, 7))) \n",
    "\n",
    "    if run:\n",
    "        try:\n",
    "            wandb.log({\"Learning Curve\": wandb.Image(plt)})\n",
    "            logger.info(\"Learning curve plot logged to Weights & Biases.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to log plot to wandb: {e}\")\n",
    "    plt.close()\n",
    "else:\n",
    "     logger.warning(\"No valid data found to generate learning curve plot.\")\n",
    "\n",
    "\n",
    "logger.info(\"\\n===== Final Benchmark Comparison =====\")\n",
    "results_list = []\n",
    "indices = []\n",
    "\n",
    "if \"Baseline\" in all_results:\n",
    "    results_list.append(all_results[\"Baseline\"])\n",
    "    indices.append(\"Baseline\")\n",
    "if \"LoRA Standard\" in all_results:\n",
    "    results_list.append(all_results[\"LoRA Standard\"])\n",
    "    indices.append(\"LoRA Standard\")\n",
    "if \"LoRA Pre-Pruned\" in all_results:\n",
    "    results_list.append(all_results[\"LoRA Pre-Pruned\"])\n",
    "    indices.append(f\"LoRA Pre-Pruned ({pruning_amount:.0%})\")\n",
    "\n",
    "if results_list:\n",
    "    df = pd.DataFrame(results_list, index=indices)\n",
    "    df_display = df.drop(columns=['ppl_log', 'steps_log'], errors='ignore')\n",
    "\n",
    "    cols_to_rename = {\n",
    "        \"steps\": \"Total Steps\", \"total_hours\": \"Total Hours (h)\",\n",
    "        \"peak_mem_mb\": \"Peak GPU Mem (MB)\", \"final_ppl\": \"Final Val PPL\"\n",
    "    }\n",
    "    if run_inference_benchmark:\n",
    "        cols_to_rename.update({\n",
    "            \"fwd_pass_latency_ms\": \"Fwd Latency (ms)\", \"fwd_pass_throughput\": \"Fwd TP (samples/s)\",\n",
    "            \"gen_latency_ms\": \"Gen Latency (ms)\", \"gen_throughput\": \"Gen TP (samples/s)\"\n",
    "        })\n",
    "\n",
    "    df_display.rename(columns=cols_to_rename, inplace=True)\n",
    "\n",
    "    format_map = {\n",
    "        \"Total Steps\": '{:,.0f}', \"Total Hours (h)\": '{:.2f}',\n",
    "        \"Peak GPU Mem (MB)\": '{:,.1f}', \"Final Val PPL\": '{:.2f}',\n",
    "        \"Fwd Latency (ms)\": '{:.1f}', \"Fwd TP (samples/s)\": '{:.1f}',\n",
    "        \"Gen Latency (ms)\": '{:.1f}', \"Gen TP (samples/s)\": '{:.1f}'\n",
    "    }\n",
    "    for col, fmt in format_map.items():\n",
    "        if col in df_display.columns:\n",
    "            try:\n",
    "                df_display[col] = df_display[col].map(lambda x: fmt.format(x) if pd.notnull(x) else 'N/A')\n",
    "            except (TypeError, ValueError):\n",
    "                 logger.warning(f\"Could not format column {col}. Skipping formatting.\")\n",
    "\n",
    "\n",
    "    logger.info(\"\\nComparison DataFrame:\\n%s\", df_display.to_string())\n",
    "\n",
    "    if run:\n",
    "        try:\n",
    "            df_log = df_display.reset_index().rename(columns={'index': 'Method'})\n",
    "            wandb.log({\"Comparison Table\": wandb.Table(dataframe=df_log)})\n",
    "            logger.info(\"Comparison table logged to Weights & Biases.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to log DataFrame to Weights & Biases: {e}\")\n",
    "\n",
    "else:\n",
    "    logger.error(\"No successful benchmark runs to compare.\")\n",
    "\n",
    "if run:\n",
    "    wandb.finish()\n",
    "    logger.info(\"Weights & Biases run finished.\")\n",
    "\n",
    "logger.info(\"\\n===== Script Finished =====\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (benim)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
